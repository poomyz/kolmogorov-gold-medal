{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2912ce2-8983-4c2e-ac83-db53af6b6bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_type = 'mels_cnn_1'\n",
    "sample_rate = 2000\n",
    "n_fft, n_hop_length = 512, 512\n",
    "window_size, hop_length = int(sample_rate*1.0), sample_rate/4\n",
    "n_mels = 256\n",
    "seed = 958"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543ffe40-6504-4351-822d-c3879b17ff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import random\n",
    "import librosa\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib as plt\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import butter, lfilter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41c7d58e-0a0d-4f71-8165-e142eeb1af0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2650,) (590,)\n"
     ]
    }
   ],
   "source": [
    "heart_sound_all = glob.glob('../../heart-new/training/*.wav')\n",
    "heart_sound, heart_sound_test = heart_sound_all[:2650], heart_sound_all[2650:]\n",
    "print(np.shape(heart_sound),np.shape(heart_sound_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "261db4d2-891c-4474-af80-291deb1d7739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2650,) (590,)\n"
     ]
    }
   ],
   "source": [
    "with open('../../heart-new/label-all/RECORDS') as file:Record=file.read().splitlines()\n",
    "\n",
    "def process_labels(folder):\n",
    "    with open(f'../../heart-new/{folder}/RECORDS') as file:\n",
    "        records = file.read().splitlines()\n",
    "    with open(f'../../heart-new/{folder}/RECORDS-normal') as file:\n",
    "        normal = set(file.read().splitlines())\n",
    "    with open(f'../../heart-new/{folder}/RECORDS-abnormal') as file:\n",
    "        abnormal = set(file.read().splitlines())\n",
    "    normal_dict = {item: 0 for item in list(normal)}\n",
    "    abnormal_dict = {item: 1 for item in list(abnormal)}\n",
    "    combined_dict = {**normal_dict, **abnormal_dict}\n",
    "    reordered_dict = {k: combined_dict[k] for k in records}\n",
    "    label_list = list(reordered_dict.values())\n",
    "    return label_list\n",
    "\n",
    "LABEL_list_all = process_labels('label-all')\n",
    "LABEL_list, LABEL_list_test = LABEL_list_all[:2650], LABEL_list_all[2650:]\n",
    "LABEL_array, LABEL_array_test = np.array(LABEL_list), np.array(LABEL_list_test)\n",
    "print(np.shape(LABEL_array), np.shape(LABEL_array_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e24a5d69-1fad-4e66-a077-8f23e24b6edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(heart_sounds, sr=sample_rate):\n",
    "    data = []\n",
    "    for i in tqdm(range(len(heart_sounds)),desc='Import data',leave=False):\n",
    "        y, sr = librosa.load(heart_sounds[i], sr=sr)\n",
    "        if len(y) >= sample_rate*5 : data.append(y[:sample_rate*5])\n",
    "        else:data.append(y)\n",
    "    return data\n",
    "    \n",
    "def augment_data(signals, labels, sr=sample_rate, fraction=1):\n",
    "    num_to_augment = int(len(signals) * fraction)\n",
    "    indices_to_augment = random.Random(seed).sample(range(len(signals)), num_to_augment)\n",
    "    aug_signals,aug_labels = [],[]\n",
    "    methods = ['pitch_shift', 'time_stretch', 'add_noise']\n",
    "    for idx in tqdm(indices_to_augment,desc='Augmenting',total=num_to_augment,leave=False):\n",
    "        signal = signals[idx]\n",
    "        label = labels[idx]\n",
    "        method = random.Random(seed).choice(methods)\n",
    "        if method == 'pitch_shift':\n",
    "            n_semitones = random.Random(seed).uniform(-2, 2)\n",
    "            augmented_signal = librosa.effects.pitch_shift(y=signal, sr=sample_rate, n_steps=n_semitones)\n",
    "        elif method == 'time_stretch':\n",
    "            rate = random.Random(seed).uniform(0.8, 1.2)\n",
    "            augmented_signal = librosa.effects.time_stretch(signal, rate=rate)\n",
    "        elif method == 'add_noise':\n",
    "            noise_factor = random.Random(seed).uniform(0.001, 0.01)\n",
    "            noise = noise_factor * np.random.Random(seed).randn(len(signal))\n",
    "            augmented_signal = signal + noise\n",
    "        aug_signals.append(augmented_signal)\n",
    "        aug_labels.append(label)\n",
    "    return signals, list(labels), aug_signals, list(aug_labels)\n",
    "\n",
    "def sliding_window(signals, labels, window_size=window_size, hop_length=hop_length):\n",
    "    segments = []\n",
    "    segment_labels = []\n",
    "    for signal, label in tqdm(zip(signals, labels),desc='Segmenting',total=len(labels),leave=False):\n",
    "        if len(signal) < window_size:\n",
    "            continue\n",
    "        num_segments = int((len(signal)-hop_length)/(window_size-hop_length))\n",
    "        for i in range(num_segments):\n",
    "            start = int(i * (window_size-hop_length))\n",
    "            end = start + window_size\n",
    "            window = signal[start:end]\n",
    "            segments.append(window)\n",
    "            segment_labels.append(label)\n",
    "    return segments, segment_labels\n",
    "\n",
    "def double_shuffle(signals, labels):\n",
    "    Z = list(zip(signals, labels))\n",
    "    random.Random(seed).shuffle(Z)\n",
    "    shuffled_data, shuffled_label = zip(*Z)\n",
    "    shuffled_data, shuffled_label = np.array(shuffled_data), np.array(shuffled_label)\n",
    "    return shuffled_data, shuffled_label\n",
    "\n",
    "def balance_classes(signals, labels):\n",
    "    signals = np.array(signals, dtype=np.float16)\n",
    "    labels = np.array(labels, dtype=np.int16)\n",
    "    undersampler = RandomUnderSampler(random_state=seed)\n",
    "    signals_resampled, labels_resampled = undersampler.fit_resample(signals, labels)\n",
    "    return signals_resampled, labels_resampled\n",
    "\n",
    "def extract_features(signals):\n",
    "    mel_spectrograms = []\n",
    "    scaler = MinMaxScaler()\n",
    "    for signal in tqdm(signals,desc='Extracting features',total=len(signals),leave=False):\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=signal, sr=sample_rate, n_fft=n_fft, hop_length=n_hop_length, n_mels=n_mels)\n",
    "        mel_spectrogram = librosa.amplitude_to_db(mel_spectrogram, ref=np.max)\n",
    "        mel_spectrogram_flat = mel_spectrogram.flatten().reshape(-1,1)\n",
    "        mel_spectrogram_normalized = scaler.fit_transform(mel_spectrogram_flat)\n",
    "        mel_spectrogram_normalized = mel_spectrogram_normalized.reshape(mel_spectrogram.shape)\n",
    "        mel_spectrogram_normalized = mel_spectrogram_normalized[..., np.newaxis]\n",
    "        mel_spectrograms.append(mel_spectrogram_normalized)\n",
    "    return np.array(mel_spectrograms, dtype=np.float32)\n",
    "\n",
    "def preprocessing(signals, labels, length=-1):\n",
    "    signals_windowed, labels_windowed = sliding_window(signals, labels)\n",
    "    signals_balanced, labels_balanced = balance_classes(signals_windowed, labels_windowed)\n",
    "    signals_shuffled, labels_shuffled = double_shuffle(signals_balanced, labels_balanced)\n",
    "    signals_reshaped, labels_reshaped = signals_shuffled[:length], labels_shuffled[:length]\n",
    "    signal = extract_features(signals_reshaped)\n",
    "    label = list(labels_reshaped)\n",
    "    return signal, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b3b44b-0067-4513-b487-8ac1959a1220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing train & validation dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreprocessing train & validation dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m DATA_array \u001b[38;5;241m=\u001b[39m load_data(heart_sound)\n\u001b[1;32m----> 3\u001b[0m Training_data, Training_label, augmented_data, augmented_label \u001b[38;5;241m=\u001b[39m \u001b[43maugment_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLABEL_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m Training_data_preprocessed, Training_label_preprocessed \u001b[38;5;241m=\u001b[39m preprocessing(Training_data, Training_label)\n\u001b[0;32m      5\u001b[0m augmented_data_preprocessed, augmented_label_preprocessed \u001b[38;5;241m=\u001b[39m preprocessing(augmented_data, augmented_label, length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mshape(Training_label_preprocessed)[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[1;32mIn[5], line 23\u001b[0m, in \u001b[0;36maugment_data\u001b[1;34m(signals, labels, sr, fraction)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_stretch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     22\u001b[0m     rate \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mRandom(seed)\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m1.2\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m     augmented_signal \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffects\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_stretch\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd_noise\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     25\u001b[0m     noise_factor \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mRandom(seed)\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0.001\u001b[39m, \u001b[38;5;241m0.01\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bhuri\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\librosa\\effects.py:387\u001b[0m, in \u001b[0;36mtime_stretch\u001b[1;34m(y, rate, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m stft \u001b[38;5;241m=\u001b[39m core\u001b[38;5;241m.\u001b[39mstft(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;66;03m# Stretch by phase vocoding\u001b[39;00m\n\u001b[1;32m--> 387\u001b[0m stft_stretch \u001b[38;5;241m=\u001b[39m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphase_vocoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhop_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_fft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# Predict the length of y_stretch\u001b[39;00m\n\u001b[0;32m    395\u001b[0m len_stretch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m rate))\n",
      "File \u001b[1;32mc:\\Users\\bhuri\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\librosa\\core\\spectrum.py:1462\u001b[0m, in \u001b[0;36mphase_vocoder\u001b[1;34m(D, rate, hop_length, n_fft)\u001b[0m\n\u001b[0;32m   1459\u001b[0m mag \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m alpha) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(columns[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m alpha \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(columns[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m   1461\u001b[0m \u001b[38;5;66;03m# Store to output array\u001b[39;00m\n\u001b[1;32m-> 1462\u001b[0m d_stretch[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, t] \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphasor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphase_acc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;66;03m# Compute phase advance\u001b[39;00m\n\u001b[0;32m   1465\u001b[0m dphase \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mangle(columns[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mangle(columns[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m-\u001b[39m phi_advance\n",
      "File \u001b[1;32mc:\\Users\\bhuri\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\librosa\\util\\utils.py:2582\u001b[0m, in \u001b[0;36mphasor\u001b[1;34m(angles, mag)\u001b[0m\n\u001b[0;32m   2524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mphasor\u001b[39m(\n\u001b[0;32m   2525\u001b[0m     angles: Union[np\u001b[38;5;241m.\u001b[39mndarray, _Real],\n\u001b[0;32m   2526\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   2527\u001b[0m     mag: Optional[Union[np\u001b[38;5;241m.\u001b[39mndarray, _Number]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2528\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mcomplex_]:\n\u001b[0;32m   2529\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct a complex phasor representation from angles.\u001b[39;00m\n\u001b[0;32m   2530\u001b[0m \n\u001b[0;32m   2531\u001b[0m \u001b[38;5;124;03m    When `mag` is not provided, this is equivalent to:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2580\u001b[0m \u001b[38;5;124;03m    array([5.000e-01+0.j , 9.185e-17+1.5j])\u001b[39;00m\n\u001b[0;32m   2581\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2582\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43m_phasor_angles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mangles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2584\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mag \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2585\u001b[0m         z \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m mag\n",
      "File \u001b[1;32mc:\\Users\\bhuri\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\numba\\np\\ufunc\\dufunc.py:288\u001b[0m, in \u001b[0;36mDUFunc.__call__\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkws)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Preprocessing train & validation dataset...\")\n",
    "DATA_array = load_data(heart_sound)\n",
    "Training_data, Training_label, augmented_data, augmented_label = augment_data(DATA_array, LABEL_array)\n",
    "Training_data_preprocessed, Training_label_preprocessed = preprocessing(Training_data, Training_label)\n",
    "augmented_data_preprocessed, augmented_label_preprocessed = preprocessing(augmented_data, augmented_label, length=10000-np.shape(Training_label_preprocessed)[0])\n",
    "DATA = np.concatenate([Training_data_preprocessed, augmented_data_preprocessed], axis=0)\n",
    "LABEL = np.array(Training_label_preprocessed + augmented_label_preprocessed, dtype=np.int32)\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "folds = list(kf.split(DATA))\n",
    "\n",
    "EVERY_Fold_data_train = [[] for i in range(k)]\n",
    "EVERY_Fold_data_val = [[] for i in range(k)]\n",
    "EVERY_Fold_label_train = [[] for i in range(k)]\n",
    "EVERY_Fold_label_val = [[] for i in range(k)]\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(folds):\n",
    "    EVERY_Fold_data_train[i].append(DATA[train_idx])\n",
    "    EVERY_Fold_label_train[i].append(LABEL[train_idx])\n",
    "    EVERY_Fold_data_val[i].append(DATA[val_idx])\n",
    "    EVERY_Fold_label_val[i].append(LABEL[val_idx])\n",
    "\n",
    "print(\"Preprocessing and fold assignment complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9e8c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(863, 256, 4, 1)\n",
      "Preprocessing complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "print(\"Preprocessing test dataset...\")\n",
    "DATA_array_test = load_data(heart_sound_test)\n",
    "Test_data, Test_label = preprocessing(DATA_array_test, LABEL_array_test)\n",
    "print(np.shape(Test_data))\n",
    "print(\"Preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe7517-c9ca-41ff-94da-ccddfc60f1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 8000, 256, 4, 1)\n",
      "(5, 8000)\n",
      "(5, 2000, 256, 4, 1)\n",
      "(5, 2000)\n"
     ]
    }
   ],
   "source": [
    "EVERY_Fold_data_train_download=[[],[],[],[],[]]\n",
    "EVERY_Fold_label_train_download=[[],[],[],[],[]]\n",
    "EVERY_Fold_data_val_download=[[],[],[],[],[]]\n",
    "EVERY_Fold_label_val_download=[[],[],[],[],[]]\n",
    "for i in range(5):EVERY_Fold_data_train_download[i] = EVERY_Fold_data_train[i][0]\n",
    "for i in range(5):EVERY_Fold_label_train_download[i] = EVERY_Fold_label_train[i][0]\n",
    "for i in range(5):EVERY_Fold_data_val_download[i] = EVERY_Fold_data_val[i][0]\n",
    "for i in range(5):EVERY_Fold_label_val_download[i] = EVERY_Fold_label_val[i][0]\n",
    "print(np.shape(EVERY_Fold_data_train_download))\n",
    "print(np.shape(EVERY_Fold_label_train_download))\n",
    "print(np.shape(EVERY_Fold_data_val_download))\n",
    "print(np.shape(EVERY_Fold_label_val_download))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237ecd5a-b3d4-4cbe-9721-c3d08977d661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data have lebel normal : 49.92% and have lebel abnormal : 50.08%\n",
      "Validation data have lebel normal : 50.65% and have lebel abnormal : 49.35%\n"
     ]
    }
   ],
   "source": [
    "train_fraction , val_fraction = len(LABEL)*(k-1)/(100*k) , len(LABEL)/(100*k)\n",
    "print(f'Train data have lebel normal : {(list(EVERY_Fold_label_train_download[0]).count(0))/train_fraction:.2f}% and have lebel abnormal : {(list(EVERY_Fold_label_train_download[0]).count(1))/train_fraction:.2f}%')\n",
    "print(f'Validation data have lebel normal : {(list(EVERY_Fold_label_val_download[0]).count(0))/val_fraction:.2f}% and have lebel abnormal : {(list(EVERY_Fold_label_val_download[0]).count(1))/val_fraction:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b170e14-d478-4827-b68c-c7148342e482",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'{DATA_type}/Train_data.npy', EVERY_Fold_data_train_download)\n",
    "np.save(f'{DATA_type}/Train_lebel.npy', EVERY_Fold_label_train_download)\n",
    "np.save(f'{DATA_type}/Val_data.npy', EVERY_Fold_data_val_download)\n",
    "np.save(f'{DATA_type}/Val_lebel.npy', EVERY_Fold_label_val_download)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
