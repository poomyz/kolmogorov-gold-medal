{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e75e7a1-9ddd-4734-8ff9-424dee2dfc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import random\n",
    "import librosa\n",
    "import itertools\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from IPython.display import clear_output\n",
    "from scipy.signal import butter, lfilter\n",
    "from tensorflow.keras import models, layers, Input\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout, Reshape, LSTM, Dense\n",
    "from tensorflow.keras.metrics import Recall\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1,l2\n",
    "from sklearn.utils import shuffle, class_weight\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b995d86-ca8f-4071-ad58-cddd7ffc7d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 8000, 20, 44, 1)\n",
      "(5, 8000)\n",
      "(5, 2000, 20, 44, 1)\n",
      "(5, 2000)\n"
     ]
    }
   ],
   "source": [
    "DATA_type = 'MFCC_cnn_1'\n",
    "Model_name = 'CNN_MFCC_1'\n",
    "Train_data=np.load(f'../Make&stored_DATA/{DATA_type}/Train_data.npy')\n",
    "Train_lebel=np.load(f'../Make&stored_DATA/{DATA_type}/Train_lebel.npy')\n",
    "Val_data=np.load(f'../Make&stored_DATA/{DATA_type}/Val_data.npy')\n",
    "Val_lebel=np.load(f'../Make&stored_DATA/{DATA_type}/Val_lebel.npy')\n",
    "print(np.shape(Train_data))\n",
    "print(np.shape(Train_lebel))\n",
    "print(np.shape(Val_data))\n",
    "print(np.shape(Val_lebel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db538c22-b56c-46b3-9699-5c174d4b4cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryBestWeights(Callback):\n",
    "    def __init__(self, monitor='val_loss', mode='min'):\n",
    "        super().__init__()\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        \n",
    "        if self.mode == 'min':\n",
    "            self.best = np.Inf\n",
    "            self.monitor_op = np.less\n",
    "        else:\n",
    "            self.best = -np.Inf\n",
    "            self.monitor_op = np.greater\n",
    "        \n",
    "        self.best_weights = None\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:return\n",
    "        if self.monitor_op(current, self.best):\n",
    "            self.best = current\n",
    "            self.best_weights = self.model.get_weights()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.best_weights is not None:\n",
    "            self.model.set_weights(self.best_weights)\n",
    "            print(f\"Restored best weights from {self.monitor} = {self.best:.4f}\")\n",
    "        else:print(\"No improvement was tracked; model weights not restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8744513c-16e3-476e-92db-44dc9c909fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running config 1/36\n",
      "Config:\n",
      "  Batch Size     : 16\n",
      "  Learning Rate  : 0.0001\n",
      "  Hidden Units   : 32\n",
      "  Dropout Rate   : 0.05\n",
      "  Kernel Reg L2  : 0.01\n",
      "----------------------------------------\n",
      "Fold : 3\n",
      "Epoch 1/100\n",
      "500/500 [==============================] - 8s 15ms/step - loss: 1.0415 - recall: 0.5644 - val_loss: 1.0009 - val_recall: 1.0000 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.9006 - recall: 0.6508 - val_loss: 0.8594 - val_recall: 0.8873 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.8156 - recall: 0.7113 - val_loss: 0.7872 - val_recall: 0.4545 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.7607 - recall: 0.7445 - val_loss: 0.7160 - val_recall: 0.6885 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.7164 - recall: 0.7536 - val_loss: 0.6766 - val_recall: 0.8557 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.6819 - recall: 0.7645 - val_loss: 0.6482 - val_recall: 0.7886 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.6548 - recall: 0.7865 - val_loss: 0.6112 - val_recall: 0.8149 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.6259 - recall: 0.8027 - val_loss: 0.6021 - val_recall: 0.9468 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.6072 - recall: 0.8058 - val_loss: 0.6022 - val_recall: 0.9714 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.5945 - recall: 0.8081 - val_loss: 0.5580 - val_recall: 0.8807 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.5790 - recall: 0.7964 - val_loss: 0.5298 - val_recall: 0.9083 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.5579 - recall: 0.8055 - val_loss: 0.6258 - val_recall: 0.9851 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.5478 - recall: 0.8093 - val_loss: 0.5313 - val_recall: 0.7480 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.5381 - recall: 0.8025 - val_loss: 0.5469 - val_recall: 0.9347 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.5267 - recall: 0.7994 - val_loss: 0.5083 - val_recall: 0.7354 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.5172 - recall: 0.7918 - val_loss: 0.4934 - val_recall: 0.7622 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.5069 - recall: 0.8108 - val_loss: 0.5290 - val_recall: 0.8802 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.5016 - recall: 0.8083 - val_loss: 0.4814 - val_recall: 0.9299 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.4901 - recall: 0.8215 - val_loss: 0.4565 - val_recall: 0.8096 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 8s 15ms/step - loss: 0.4822 - recall: 0.8202 - val_loss: 0.5167 - val_recall: 0.9683 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.4809 - recall: 0.8212 - val_loss: 0.5178 - val_recall: 0.7678 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.4737 - recall: 0.8334 - val_loss: 0.4906 - val_recall: 0.9539 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.4722 - recall: 0.8238 - val_loss: 0.4394 - val_recall: 0.9385 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.4601 - recall: 0.8349 - val_loss: 0.4772 - val_recall: 0.9802 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.4539 - recall: 0.8384 - val_loss: 0.4894 - val_recall: 0.9610 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.4528 - recall: 0.8412 - val_loss: 0.5470 - val_recall: 0.5938 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.4544 - recall: 0.8402 - val_loss: 0.4305 - val_recall: 0.9547 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.4410 - recall: 0.8516 - val_loss: 0.4141 - val_recall: 0.8379 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.4358 - recall: 0.8397 - val_loss: 0.5229 - val_recall: 0.6982 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.4345 - recall: 0.8427 - val_loss: 0.4102 - val_recall: 0.8564 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.4290 - recall: 0.8430 - val_loss: 0.4038 - val_recall: 0.8329 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.4266 - recall: 0.8496 - val_loss: 0.4638 - val_recall: 0.7620 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.4260 - recall: 0.8420 - val_loss: 0.3956 - val_recall: 0.9017 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.4174 - recall: 0.8508 - val_loss: 0.5999 - val_recall: 0.6034 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.4121 - recall: 0.8529 - val_loss: 0.4673 - val_recall: 0.9395 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.4127 - recall: 0.8443 - val_loss: 0.4293 - val_recall: 0.8263 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.4056 - recall: 0.8569 - val_loss: 0.4844 - val_recall: 0.9278 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.4036 - recall: 0.8508 - val_loss: 0.3857 - val_recall: 0.9357 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.4021 - recall: 0.8615 - val_loss: 0.3659 - val_recall: 0.8997 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.3994 - recall: 0.8496 - val_loss: 0.4166 - val_recall: 0.7926 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.3937 - recall: 0.8549 - val_loss: 0.3716 - val_recall: 0.8843 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.3865 - recall: 0.8686 - val_loss: 0.4399 - val_recall: 0.8427 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3878 - recall: 0.8660 - val_loss: 0.3549 - val_recall: 0.8830 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3831 - recall: 0.8650 - val_loss: 0.4162 - val_recall: 0.8650 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3786 - recall: 0.8688 - val_loss: 0.3413 - val_recall: 0.8683 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3689 - recall: 0.8676 - val_loss: 0.3669 - val_recall: 0.8762 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3688 - recall: 0.8739 - val_loss: 0.3258 - val_recall: 0.9106 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3648 - recall: 0.8779 - val_loss: 0.3556 - val_recall: 0.8156 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3667 - recall: 0.8678 - val_loss: 0.3612 - val_recall: 0.9238 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3640 - recall: 0.8764 - val_loss: 0.4701 - val_recall: 0.6997 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3542 - recall: 0.8840 - val_loss: 0.3504 - val_recall: 0.8364 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3579 - recall: 0.8719 - val_loss: 0.5726 - val_recall: 0.5586 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3333 - recall: 0.8815 - val_loss: 0.3171 - val_recall: 0.8845 - lr: 2.0000e-05\n",
      "Epoch 54/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3274 - recall: 0.8979 - val_loss: 0.3219 - val_recall: 0.8590 - lr: 2.0000e-05\n",
      "Epoch 55/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3281 - recall: 0.8878 - val_loss: 0.3042 - val_recall: 0.8749 - lr: 2.0000e-05\n",
      "Epoch 56/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3291 - recall: 0.8866 - val_loss: 0.3238 - val_recall: 0.8501 - lr: 2.0000e-05\n",
      "Epoch 57/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3253 - recall: 0.8969 - val_loss: 0.3020 - val_recall: 0.9126 - lr: 2.0000e-05\n",
      "Epoch 58/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3260 - recall: 0.8873 - val_loss: 0.3169 - val_recall: 0.8673 - lr: 2.0000e-05\n",
      "Epoch 59/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3214 - recall: 0.8886 - val_loss: 0.3466 - val_recall: 0.8326 - lr: 2.0000e-05\n",
      "Epoch 60/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3230 - recall: 0.8974 - val_loss: 0.3300 - val_recall: 0.8478 - lr: 2.0000e-05\n",
      "Epoch 61/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3235 - recall: 0.8952 - val_loss: 0.3067 - val_recall: 0.8536 - lr: 2.0000e-05\n",
      "Epoch 62/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3223 - recall: 0.8939 - val_loss: 0.3232 - val_recall: 0.8425 - lr: 2.0000e-05\n",
      "Epoch 63/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3152 - recall: 0.8898 - val_loss: 0.2888 - val_recall: 0.9154 - lr: 4.0000e-06\n",
      "Epoch 64/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3178 - recall: 0.8957 - val_loss: 0.2924 - val_recall: 0.9002 - lr: 4.0000e-06\n",
      "Epoch 65/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3181 - recall: 0.9000 - val_loss: 0.3012 - val_recall: 0.8843 - lr: 4.0000e-06\n",
      "Epoch 66/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3144 - recall: 0.9002 - val_loss: 0.2907 - val_recall: 0.9104 - lr: 4.0000e-06\n",
      "Epoch 67/100\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.3121 - recall: 0.8972 - val_loss: 0.2923 - val_recall: 0.9023 - lr: 4.0000e-06\n",
      "Epoch 68/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3130 - recall: 0.9015 - val_loss: 0.2937 - val_recall: 0.8871 - lr: 4.0000e-06\n",
      "Epoch 69/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3122 - recall: 0.8957 - val_loss: 0.2890 - val_recall: 0.9033 - lr: 1.0000e-06\n",
      "Epoch 70/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3114 - recall: 0.8974 - val_loss: 0.2899 - val_recall: 0.9007 - lr: 1.0000e-06\n",
      "Epoch 71/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3176 - recall: 0.8942 - val_loss: 0.2890 - val_recall: 0.9005 - lr: 1.0000e-06\n",
      "Epoch 72/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3148 - recall: 0.8985 - val_loss: 0.2906 - val_recall: 0.8967 - lr: 1.0000e-06\n",
      "Epoch 73/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3102 - recall: 0.9035 - val_loss: 0.2898 - val_recall: 0.8977 - lr: 1.0000e-06\n",
      "Epoch 74/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3123 - recall: 0.8974 - val_loss: 0.2887 - val_recall: 0.9030 - lr: 1.0000e-06\n",
      "Epoch 75/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3110 - recall: 0.9010 - val_loss: 0.2884 - val_recall: 0.9023 - lr: 1.0000e-06\n",
      "Epoch 76/100\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.3170 - recall: 0.8974 - val_loss: 0.2885 - val_recall: 0.9025 - lr: 1.0000e-06\n",
      "Epoch 77/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3096 - recall: 0.9030 - val_loss: 0.2896 - val_recall: 0.9000 - lr: 1.0000e-06\n",
      "Epoch 78/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3132 - recall: 0.9025 - val_loss: 0.2891 - val_recall: 0.8990 - lr: 1.0000e-06\n",
      "Epoch 79/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3121 - recall: 0.9028 - val_loss: 0.2885 - val_recall: 0.9015 - lr: 1.0000e-06\n",
      "Epoch 80/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3147 - recall: 0.8936 - val_loss: 0.2868 - val_recall: 0.9081 - lr: 1.0000e-06\n",
      "Epoch 81/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3116 - recall: 0.9030 - val_loss: 0.2868 - val_recall: 0.9023 - lr: 1.0000e-06\n",
      "Epoch 82/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3144 - recall: 0.9010 - val_loss: 0.2881 - val_recall: 0.8982 - lr: 1.0000e-06\n",
      "Epoch 83/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3111 - recall: 0.8985 - val_loss: 0.2873 - val_recall: 0.9000 - lr: 1.0000e-06\n",
      "Epoch 84/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3133 - recall: 0.8995 - val_loss: 0.2885 - val_recall: 0.9000 - lr: 1.0000e-06\n",
      "Epoch 85/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3141 - recall: 0.8990 - val_loss: 0.2882 - val_recall: 0.9038 - lr: 1.0000e-06\n",
      "Epoch 86/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3126 - recall: 0.8982 - val_loss: 0.2895 - val_recall: 0.8985 - lr: 1.0000e-06\n",
      "Epoch 87/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3161 - recall: 0.9035 - val_loss: 0.2904 - val_recall: 0.8969 - lr: 1.0000e-06\n",
      "Epoch 88/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3095 - recall: 0.9023 - val_loss: 0.2882 - val_recall: 0.9017 - lr: 1.0000e-06\n",
      "Epoch 89/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3113 - recall: 0.9017 - val_loss: 0.2881 - val_recall: 0.9000 - lr: 1.0000e-06\n",
      "Epoch 90/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3141 - recall: 0.8957 - val_loss: 0.2879 - val_recall: 0.9030 - lr: 1.0000e-06\n",
      "Epoch 91/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3131 - recall: 0.8979 - val_loss: 0.2873 - val_recall: 0.9010 - lr: 1.0000e-06\n",
      "Epoch 92/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3125 - recall: 0.8995 - val_loss: 0.2877 - val_recall: 0.9020 - lr: 1.0000e-06\n",
      "Epoch 93/100\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.3135 - recall: 0.8929 - val_loss: 0.2879 - val_recall: 0.9020 - lr: 1.0000e-06\n",
      "Epoch 94/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3126 - recall: 0.8995 - val_loss: 0.2883 - val_recall: 0.9010 - lr: 1.0000e-06\n",
      "Epoch 95/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3117 - recall: 0.8982 - val_loss: 0.2870 - val_recall: 0.9033 - lr: 1.0000e-06\n",
      "Epoch 96/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3087 - recall: 0.9035 - val_loss: 0.2872 - val_recall: 0.9040 - lr: 1.0000e-06\n",
      "Epoch 97/100\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.3124 - recall: 0.8959 - val_loss: 0.2867 - val_recall: 0.9063 - lr: 1.0000e-06\n",
      "Epoch 98/100\n",
      "500/500 [==============================] - 6s 13ms/step - loss: 0.3127 - recall: 0.9043 - val_loss: 0.2853 - val_recall: 0.9099 - lr: 1.0000e-06\n",
      "Epoch 99/100\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.3102 - recall: 0.9010 - val_loss: 0.2894 - val_recall: 0.8987 - lr: 1.0000e-06\n",
      "Epoch 100/100\n",
      "500/500 [==============================] - 7s 13ms/step - loss: 0.3129 - recall: 0.9005 - val_loss: 0.2875 - val_recall: 0.9023 - lr: 1.0000e-06\n",
      "Restored best weights from val_recall = 1.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m epoch_recalls \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m---> 66\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m (\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     67\u001b[0m     recall \u001b[38;5;241m=\u001b[39m recall_score(y_val, y_pred)\n\u001b[0;32m     68\u001b[0m     epoch_recalls\u001b[38;5;241m.\u001b[39mappend(recall)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py:2253\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   2252\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 2253\u001b[0m     tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   2255\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.makedirs(\"grid_search_outputs\", exist_ok=True)\n",
    "\n",
    "batch_sizes = [16]\n",
    "learning_rates = [0.0001, 0.0005, 0.001]\n",
    "hidden_units = [32, 64, 128]\n",
    "dropouts = [0.05, 0.1]\n",
    "kernel_regs = [0.01, 0.02]\n",
    "\n",
    "param_combinations = list(itertools.product(batch_sizes, learning_rates, hidden_units, dropouts, kernel_regs))\n",
    "\n",
    "results = []\n",
    "best_model = None\n",
    "best_model_config_id = None\n",
    "best_model_recall = 0\n",
    "\n",
    "for i, (batch_size, lr, hidden_size, dropout_rate, kernel_reg) in enumerate(param_combinations):\n",
    "    fold_recalls = []\n",
    "    fold_best_histories = []\n",
    "    fold_best_cms = []\n",
    "\n",
    "    for fold in range(5):\n",
    "        print(f\"Running config {i+1}/{len(param_combinations)}\")\n",
    "        print(\"Config:\")\n",
    "        print(f\"  Batch Size     : {batch_size}\")\n",
    "        print(f\"  Learning Rate  : {lr}\")\n",
    "        print(f\"  Hidden Units   : {hidden_size}\")\n",
    "        print(f\"  Dropout Rate   : {dropout_rate}\")\n",
    "        print(f\"  Kernel Reg L2  : {kernel_reg}\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Fold : {fold+1}\")\n",
    "        X_train, X_val = Train_data[fold], Train_data[fold]\n",
    "        y_train, y_val = Train_lebel[fold], Train_lebel[fold]\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        model = models.Sequential([\n",
    "            Input(shape=np.shape(Train_data[0][0])),\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(kernel_reg)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(kernel_reg)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(hidden_size, activation='relu'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=[Recall(name='recall')])\n",
    "\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=0)\n",
    "        memory_best = MemoryBestWeights(monitor='val_recall', mode='max')\n",
    "\n",
    "        history = model.fit(X_train, y_train,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                            epochs=100,\n",
    "                            batch_size=batch_size,\n",
    "                            callbacks=[reduce_lr, memory_best],\n",
    "                            verbose=1)\n",
    "\n",
    "        epoch_recalls = []\n",
    "        for epoch in range(100):\n",
    "            y_pred = (model.predict(X_val, verbose=0) > 0.5).astype(\"int32\")\n",
    "            recall = recall_score(y_val, y_pred)\n",
    "            epoch_recalls.append(recall)\n",
    "\n",
    "        best_epoch = int(np.argmax(epoch_recalls))\n",
    "        best_recall = epoch_recalls[best_epoch]\n",
    "\n",
    "        fold_recalls.append(best_recall)\n",
    "        fold_best_histories.append(history)\n",
    "        y_pred = (model.predict(X_val, verbose=0) > 0.5).astype(\"int32\")\n",
    "        cm = confusion_matrix(y_val, y_pred)\n",
    "        fold_best_cms.append((cm, y_val, y_pred))\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "\n",
    "    best_fold = int(np.argmax(fold_recalls))\n",
    "    avg_recall = np.mean(fold_recalls)\n",
    "\n",
    "    best_history = fold_best_histories[best_fold]\n",
    "    best_cm, best_y_val, best_y_pred = fold_best_cms[best_fold]\n",
    "\n",
    "    results.append({\n",
    "        'config_id': i,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': lr,\n",
    "        'hidden_size': hidden_size,\n",
    "        'dropout': dropout_rate,\n",
    "        'kernel_reg': kernel_reg,\n",
    "        'avg_val_recall': avg_recall,\n",
    "        'best_fold_recall': fold_recalls[best_fold],\n",
    "        'history': best_history,\n",
    "        'confusion_matrix': best_cm\n",
    "    })\n",
    "\n",
    "    if avg_recall > best_model_recall:\n",
    "        best_model_recall = avg_recall\n",
    "        best_model_config_id = i\n",
    "        best_model = {\n",
    "            'history': best_history,\n",
    "            'confusion_matrix': best_cm,\n",
    "            'model': model\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5477322a-ee50-4fdf-ae92-450ac514676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sorted(results, key=lambda x: x['avg_val_recall'], reverse=True)\n",
    "\n",
    "print(\"Best Model Metric\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Config ID        : {best_model_config_id}\")\n",
    "print(f\"Batch Size       : {results[best_model_config_id]['batch_size']}\")\n",
    "print(f\"Learning Rate    : {results[best_model_config_id]['learning_rate']}\")\n",
    "print(f\"Hidden Units     : {results[best_model_config_id]['hidden_size']}\")\n",
    "print(f\"Dropout Rate     : {results[best_model_config_id]['dropout']}\")\n",
    "print(f\"Kernel Reg L2    : {results[best_model_config_id]['kernel_reg']}\")\n",
    "print(f\"Avg Recall (5-fold): {results[best_model_config_id]['avg_val_recall']:.4f}\")\n",
    "print(f\"Best Fold Recall : {results[best_model_config_id]['best_fold_recall']:.4f}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "best_history = best_model['history']\n",
    "best_cm = best_model['confusion_matrix']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].plot(best_history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in best_history.history:\n",
    "    axes[0, 0].plot(best_history.history['val_loss'], label='Validation Loss')\n",
    "axes[0, 0].set_title('Model Loss')\n",
    "axes[0, 0].set_xlabel('Epochs')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "if 'recall' in best_history.history:\n",
    "    axes[0, 1].plot(best_history.history['recall'], label='Training Accuracy')\n",
    "if 'val_recall' in best_history.history:\n",
    "    axes[0, 1].plot(best_history.history['val_recall'], label='Validation Accuracy')\n",
    "axes[0, 1].set_title('Model Accuracy')\n",
    "axes[0, 1].set_xlabel('Epochs')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "if 'lr' in best_history.history:\n",
    "    axes[1, 0].plot(best_history.history['lr'], label='Learning Rate')\n",
    "elif 'learning_rate' in best_history.history:\n",
    "    axes[1, 0].plot(best_history.history['learning_rate'], label='Learning Rate')\n",
    "axes[1, 0].set_title('Learning Rate')\n",
    "axes[1, 0].set_xlabel('Epochs')\n",
    "axes[1, 0].set_ylabel('Learning Rate')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=best_cm, display_labels=[\"Normal\", \"Abnormal\"])\n",
    "disp.plot(cmap=plt.cm.Blues, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Best Model Confusion Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba03cb63-e14d-4076-85a0-1295e0b7019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_best_fold_model = sorted(results, key=lambda x: x['best_fold_recall'], reverse=True)[0]\n",
    "\n",
    "print(\"Best Single-Fold Recall Model\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Config ID          : {top_best_fold_model['config_id']}\")\n",
    "print(f\"Batch Size         : {top_best_fold_model['batch_size']}\")\n",
    "print(f\"Learning Rate      : {top_best_fold_model['learning_rate']}\")\n",
    "print(f\"Hidden Units       : {top_best_fold_model['hidden_size']}\")\n",
    "print(f\"Dropout Rate       : {top_best_fold_model['dropout']}\")\n",
    "print(f\"Kernel Reg L2      : {top_best_fold_model['kernel_reg']}\")\n",
    "print(f\"Best Fold Recall   : {top_best_fold_model['best_fold_recall']:.4f}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "top_best_history = top_best_fold_model['history']\n",
    "top_best_cm = top_best_fold_model['confusion_matrix']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].plot(top_best_history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in top_best_history.history:\n",
    "    axes[0, 0].plot(top_best_history.history['val_loss'], label='Validation Loss')\n",
    "axes[0, 0].set_title('Model Loss (Best Recall Fold)')\n",
    "axes[0, 0].set_xlabel('Epochs')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "if 'recall' in top_best_history.history:\n",
    "    axes[0, 1].plot(top_best_history.history['recall'], label='Training Recall')\n",
    "if 'val_recall' in top_best_history.history:\n",
    "    axes[0, 1].plot(top_best_history.history['val_recall'], label='Validation Recall')\n",
    "axes[0, 1].set_title('Model Recall (Best Recall Fold)')\n",
    "axes[0, 1].set_xlabel('Epochs')\n",
    "axes[0, 1].set_ylabel('Recall')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "if 'lr' in top_best_history.history:\n",
    "    axes[1, 0].plot(top_best_history.history['lr'], label='Learning Rate')\n",
    "elif 'learning_rate' in top_best_history.history:\n",
    "    axes[1, 0].plot(top_best_history.history['learning_rate'], label='Learning Rate')\n",
    "axes[1, 0].set_title('Learning Rate')\n",
    "axes[1, 0].set_xlabel('Epochs')\n",
    "axes[1, 0].set_ylabel('Learning Rate')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=top_best_cm, display_labels=[\"Normal\", \"Abnormal\"])\n",
    "disp.plot(cmap=plt.cm.Blues, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Confusion Matrix (Best Recall Fold)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b5823-1dbf-4e24-9019-7ca6399e8b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model['model'].save(f'../new_model/{Model_name}.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
