{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e75e7a1-9ddd-4734-8ff9-424dee2dfc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import random\n",
    "import librosa\n",
    "import itertools\n",
    "import IPython.display\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib as plt\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from scipy.signal import butter, lfilter\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.keras import models, layers, Input\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout, Reshape, LSTM, Dense\n",
    "from tensorflow.keras.metrics import Recall, Metric\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau, Callback\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1,l2\n",
    "from sklearn.utils import shuffle, class_weight\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b995d86-ca8f-4071-ad58-cddd7ffc7d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 8000, 256, 4, 1)\n",
      "(5, 8000)\n",
      "(5, 2000, 256, 4, 1)\n",
      "(5, 2000)\n"
     ]
    }
   ],
   "source": [
    "DATA_type = 'mels_cnn_1'\n",
    "Model_name = 'crnn_mels_1'\n",
    "Train_data=np.load(f'../make_stored_data/{DATA_type}/Train_data.npy')\n",
    "Train_lebel=np.load(f'../make_stored_data/{DATA_type}/Train_lebel.npy')\n",
    "Val_data=np.load(f'../make_stored_data/{DATA_type}/Val_data.npy')\n",
    "Val_lebel=np.load(f'../make_stored_data/{DATA_type}/Val_lebel.npy')\n",
    "print(np.shape(Train_data))\n",
    "print(np.shape(Train_lebel))\n",
    "print(np.shape(Val_data))\n",
    "print(np.shape(Val_lebel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db538c22-b56c-46b3-9699-5c174d4b4cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryBestWeights(Callback):\n",
    "    def __init__(self, monitor='val_loss', mode='min'):\n",
    "        super().__init__()\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        \n",
    "        if self.mode == 'min':\n",
    "            self.best = np.Inf\n",
    "            self.monitor_op = np.less\n",
    "        else:\n",
    "            self.best = -np.Inf\n",
    "            self.monitor_op = np.greater\n",
    "        \n",
    "        self.best_weights = None\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:return\n",
    "        if self.monitor_op(current, self.best):\n",
    "            self.best = current\n",
    "            self.best_weights = self.model.get_weights()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.best_weights is not None:\n",
    "            self.model.set_weights(self.best_weights)\n",
    "            print(f\"Restored best weights from {self.monitor} = {self.best:.4f}\")\n",
    "        else:print(\"No improvement was tracked; model weights not restored.\")\n",
    "\n",
    "class F2Score(Metric):\n",
    "    def __init__(self, name='f2_score', threshold=0.5, **kwargs):\n",
    "        super(F2Score, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.tp = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.fp = self.add_weight(name='fp', initializer='zeros')\n",
    "        self.fn = self.add_weight(name='fn', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = K.cast(y_pred > self.threshold, 'float32')\n",
    "        y_true = K.cast(y_true, 'float32')\n",
    "\n",
    "        tp = K.sum(y_true * y_pred)\n",
    "        fp = K.sum((1 - y_true) * y_pred)\n",
    "        fn = K.sum(y_true * (1 - y_pred))\n",
    "\n",
    "        self.tp.assign_add(tp)\n",
    "        self.fp.assign_add(fp)\n",
    "        self.fn.assign_add(fn)\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.tp / (self.tp + self.fp + K.epsilon())\n",
    "        recall = self.tp / (self.tp + self.fn + K.epsilon())\n",
    "        return 5 * (precision * recall) / (4 * precision + recall + K.epsilon())\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.tp.assign(0)\n",
    "        self.fp.assign(0)\n",
    "        self.fn.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9ce3d97-ab83-4255-b1da-8ff7eb143740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running config 1/36\n",
      "Config:\n",
      "  Batch Size     : 16\n",
      "  Learning Rate  : 0.0001\n",
      "  Hidden Units   : 32\n",
      "  Dropout Rate   : 0.05\n",
      "  Kernel Reg L2  : 0.01\n",
      "----------------------------------------\n",
      "Fold : 1\n",
      "Epoch 1/100\n",
      "498/500 [============================>.] - ETA: 0s - loss: 0.9639 - f2_score: 0.6782       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhuri\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py:2319: UserWarning: Metric F2Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  m.reset_state()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 19s 31ms/step - loss: 0.9635 - f2_score: 0.6771 - val_loss: 0.8463 - val_f2_score: 0.1498 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.7910 - f2_score: 0.6092 - val_loss: 0.7527 - val_f2_score: 0.3480 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.7369 - f2_score: 0.5976 - val_loss: 0.7177 - val_f2_score: 0.7906 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 14s 28ms/step - loss: 0.7131 - f2_score: 0.5544 - val_loss: 0.7044 - val_f2_score: 0.7744 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.6994 - f2_score: 0.5747 - val_loss: 0.6951 - val_f2_score: 0.8137 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "500/500 [==============================] - 14s 28ms/step - loss: 0.6863 - f2_score: 0.6089 - val_loss: 0.6762 - val_f2_score: 0.7513 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "500/500 [==============================] - 14s 28ms/step - loss: 0.6710 - f2_score: 0.6368 - val_loss: 0.6677 - val_f2_score: 0.5086 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "500/500 [==============================] - 16s 32ms/step - loss: 0.6558 - f2_score: 0.6597 - val_loss: 0.6290 - val_f2_score: 0.5977 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "500/500 [==============================] - 16s 31ms/step - loss: 0.6245 - f2_score: 0.7209 - val_loss: 0.6651 - val_f2_score: 0.5417 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.5826 - f2_score: 0.7749 - val_loss: 0.6431 - val_f2_score: 0.8594 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "500/500 [==============================] - 13s 27ms/step - loss: 0.5435 - f2_score: 0.8101 - val_loss: 0.5210 - val_f2_score: 0.8813 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.5121 - f2_score: 0.8324 - val_loss: 0.6959 - val_f2_score: 0.8658 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.4911 - f2_score: 0.8331 - val_loss: 0.4734 - val_f2_score: 0.8715 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.4817 - f2_score: 0.8393 - val_loss: 1.3763 - val_f2_score: 0.1008 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "500/500 [==============================] - 14s 28ms/step - loss: 0.4735 - f2_score: 0.8396 - val_loss: 2.5554 - val_f2_score: 0.0124 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.4631 - f2_score: 0.8489 - val_loss: 0.4122 - val_f2_score: 0.8883 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.4515 - f2_score: 0.8466 - val_loss: 0.6901 - val_f2_score: 0.4955 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "500/500 [==============================] - 15s 29ms/step - loss: 0.4499 - f2_score: 0.8449 - val_loss: 1.0097 - val_f2_score: 0.8558 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "500/500 [==============================] - 14s 28ms/step - loss: 0.4478 - f2_score: 0.8439 - val_loss: 1.2945 - val_f2_score: 0.1720 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.4417 - f2_score: 0.8457 - val_loss: 0.7193 - val_f2_score: 0.4510 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "500/500 [==============================] - 14s 28ms/step - loss: 0.4402 - f2_score: 0.8487 - val_loss: 0.5730 - val_f2_score: 0.5925 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "500/500 [==============================] - 14s 28ms/step - loss: 0.4247 - f2_score: 0.8569 - val_loss: 0.4128 - val_f2_score: 0.9121 - lr: 2.0000e-05\n",
      "Epoch 23/100\n",
      "500/500 [==============================] - 15s 30ms/step - loss: 0.4219 - f2_score: 0.8577 - val_loss: 0.4031 - val_f2_score: 0.8033 - lr: 2.0000e-05\n",
      "Epoch 24/100\n",
      "498/500 [============================>.] - ETA: 0s - loss: 0.4270 - f2_score: 0.8513 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     64\u001b[0m memory_best \u001b[38;5;241m=\u001b[39m MemoryBestWeights(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_recall\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 66\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_best\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m epoch_recalls \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     74\u001b[0m epoch_precisions \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py:1606\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1593\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1594\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1604\u001b[0m         steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution,\n\u001b[0;32m   1605\u001b[0m     )\n\u001b[1;32m-> 1606\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1619\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1620\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1621\u001b[0m }\n\u001b[0;32m   1622\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py:1942\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1940\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[0;32m   1941\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m-> 1942\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1943\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1944\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1945\u001b[0m         ):\n\u001b[0;32m   1946\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\data_adapter.py:1374\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1374\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1375\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1376\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[0;32m   1379\u001b[0m )\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    636\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    638\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    639\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model_f2 = 0\n",
    "fold_f2_scores = []\n",
    "\n",
    "os.makedirs(\"grid_search_outputs\", exist_ok=True)\n",
    "\n",
    "batch_sizes = [16]\n",
    "learning_rates = [0.0001, 0.0005, 0.001]\n",
    "hidden_units = [32, 64, 128]\n",
    "dropouts = [0.05, 0.1]\n",
    "kernel_regs = [0.01, 0.02]\n",
    "\n",
    "param_combinations = list(itertools.product(batch_sizes, learning_rates, hidden_units, dropouts, kernel_regs))\n",
    "\n",
    "results = []\n",
    "best_model = None\n",
    "best_model_config_id = None\n",
    "best_model_recall = 0\n",
    "\n",
    "for i, (batch_size, lr, hidden_size, dropout_rate, kernel_reg) in enumerate(param_combinations):\n",
    "    fold_recalls = []\n",
    "    fold_best_histories = []\n",
    "    fold_best_cms = []\n",
    "\n",
    "    for fold in range(5):\n",
    "        print(f\"Running config {i+1}/{len(param_combinations)}\")\n",
    "        print(\"Config:\")\n",
    "        print(f\"  Batch Size     : {batch_size}\")\n",
    "        print(f\"  Learning Rate  : {lr}\")\n",
    "        print(f\"  Hidden Units   : {hidden_size}\")\n",
    "        print(f\"  Dropout Rate   : {dropout_rate}\")\n",
    "        print(f\"  Kernel Reg L2  : {kernel_reg}\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Fold : {fold+1}\")\n",
    "        X_train, X_val = Train_data[fold], Train_data[fold]\n",
    "        y_train, y_val = Train_lebel[fold], Train_lebel[fold]\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        model = models.Sequential([\n",
    "            Input(shape=np.shape(Train_data[0][0])),\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(kernel_reg)),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(kernel_reg)),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.TimeDistributed(layers.Flatten()),\n",
    "            layers.LSTM(32, return_sequences=False),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(hidden_size, activation='relu'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=[F2Score(name='f2_score')])\n",
    "\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=0)\n",
    "        memory_best = MemoryBestWeights(monitor='val_recall', mode='max')\n",
    "\n",
    "        history = model.fit(X_train, y_train,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                            epochs=100,\n",
    "                            batch_size=batch_size,\n",
    "                            callbacks=[reduce_lr, memory_best],\n",
    "                            verbose=1)\n",
    "\n",
    "        epoch_recalls = []\n",
    "        epoch_precisions = []\n",
    "        epoch_f2_scores = []\n",
    "        for epoch in range(100):\n",
    "            y_pred = (model.predict(X_val, verbose=0) > 0.3).astype('int32')\n",
    "            recall = recall_score(y_val, y_pred)\n",
    "            precision = precision_score(y_val, y_pred)\n",
    "            f2 = custom_f2(recall, precision)\n",
    "            epoch_recalls.append(recall)\n",
    "            epoch_precisions.append(precision)\n",
    "            epoch_f2_scores.append(f2)\n",
    "\n",
    "            y_pred = (model.predict(X_val, verbose=0) > 0.5).astype(\"int32\")\n",
    "            recall = recall_score(y_val, y_pred)\n",
    "            epoch_recalls.append(recall)\n",
    "\n",
    "        best_epoch = int(np.argmax(epoch_f2_scores))\n",
    "        best_f2 = epoch_f2_scores[best_epoch]\n",
    "        best_recall = epoch_recalls[best_epoch]\n",
    "\n",
    "        fold_recalls.append(best_recall)\n",
    "        fold_f2_scores.append(best_f2)\n",
    "        fold_best_histories.append(history)\n",
    "        y_pred = (model.predict(X_val, verbose=0) > 0.5).astype(\"int32\")\n",
    "        cm = confusion_matrix(y_val, y_pred)\n",
    "        fold_best_cms.append((cm, y_val, y_pred))\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "\n",
    "    best_fold = int(np.argmax(fold_f2_scores))\n",
    "    avg_f2 = np.mean(fold_f2_scores)\n",
    "    avg_recall = np.mean(fold_recalls)\n",
    "\n",
    "    best_history = fold_best_histories[best_fold]\n",
    "    best_cm, best_y_val, best_y_pred = fold_best_cms[best_fold]\n",
    "\n",
    "    results.append({\n",
    "        'config_id': i,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': lr,\n",
    "        'hidden_size': hidden_size,\n",
    "        'dropout': dropout_rate,\n",
    "        'kernel_reg': kernel_reg,\n",
    "        'avg_val_recall': avg_recall,\n",
    "        'best_fold_recall': fold_recalls[best_fold],\n",
    "        'history': best_history,\n",
    "        'confusion_matrix': best_cm\n",
    "    })\n",
    "\n",
    "    if avg_f2 > best_model_f2:\n",
    "        best_model_f2 = avg_f2\n",
    "        best_model_config_id = i\n",
    "        best_model = {\n",
    "            'history': best_history,\n",
    "            'confusion_matrix': best_cm,\n",
    "            'model': model\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5477322a-ee50-4fdf-ae92-450ac514676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sorted(results, key=lambda x: x['avg_val_recall'], reverse=True)\n",
    "\n",
    "print(\"Best Model Metric\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Config ID        : {best_model_config_id}\")\n",
    "print(f\"Batch Size       : {results[best_model_config_id]['batch_size']}\")\n",
    "print(f\"Learning Rate    : {results[best_model_config_id]['learning_rate']}\")\n",
    "print(f\"Hidden Units     : {results[best_model_config_id]['hidden_size']}\")\n",
    "print(f\"Dropout Rate     : {results[best_model_config_id]['dropout']}\")\n",
    "print(f\"Kernel Reg L2    : {results[best_model_config_id]['kernel_reg']}\")\n",
    "print(f\"Avg Recall (5-fold): {results[best_model_config_id]['avg_val_recall']:.4f}\")\n",
    "print(f\"Best Fold Recall : {results[best_model_config_id]['best_fold_recall']:.4f}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "best_history = best_model['history']\n",
    "best_cm = best_model['confusion_matrix']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].plot(best_history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in best_history.history:\n",
    "    axes[0, 0].plot(best_history.history['val_loss'], label='Validation Loss')\n",
    "axes[0, 0].set_title('Model Loss')\n",
    "axes[0, 0].set_xlabel('Epochs')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "if 'recall' in best_history.history:\n",
    "    axes[0, 1].plot(best_history.history['recall'], label='Training Accuracy')\n",
    "if 'val_recall' in best_history.history:\n",
    "    axes[0, 1].plot(best_history.history['val_recall'], label='Validation Accuracy')\n",
    "axes[0, 1].set_title('Model Accuracy')\n",
    "axes[0, 1].set_xlabel('Epochs')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "if 'lr' in best_history.history:\n",
    "    axes[1, 0].plot(best_history.history['lr'], label='Learning Rate')\n",
    "elif 'learning_rate' in best_history.history:\n",
    "    axes[1, 0].plot(best_history.history['learning_rate'], label='Learning Rate')\n",
    "axes[1, 0].set_title('Learning Rate')\n",
    "axes[1, 0].set_xlabel('Epochs')\n",
    "axes[1, 0].set_ylabel('Learning Rate')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=best_cm, display_labels=[\"Normal\", \"Abnormal\"])\n",
    "disp.plot(cmap=plt.cm.Blues, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Best Model Confusion Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba03cb63-e14d-4076-85a0-1295e0b7019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_best_fold_model = sorted(results, key=lambda x: x['best_fold_recall'], reverse=True)[0]\n",
    "\n",
    "print(\"Best Single-Fold Recall Model\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Config ID          : {top_best_fold_model['config_id']}\")\n",
    "print(f\"Batch Size         : {top_best_fold_model['batch_size']}\")\n",
    "print(f\"Learning Rate      : {top_best_fold_model['learning_rate']}\")\n",
    "print(f\"Hidden Units       : {top_best_fold_model['hidden_size']}\")\n",
    "print(f\"Dropout Rate       : {top_best_fold_model['dropout']}\")\n",
    "print(f\"Kernel Reg L2      : {top_best_fold_model['kernel_reg']}\")\n",
    "print(f\"Best Fold Recall   : {top_best_fold_model['best_fold_recall']:.4f}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "top_best_history = top_best_fold_model['history']\n",
    "top_best_cm = top_best_fold_model['confusion_matrix']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].plot(top_best_history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in top_best_history.history:\n",
    "    axes[0, 0].plot(top_best_history.history['val_loss'], label='Validation Loss')\n",
    "axes[0, 0].set_title('Model Loss (Best Recall Fold)')\n",
    "axes[0, 0].set_xlabel('Epochs')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "if 'recall' in top_best_history.history:\n",
    "    axes[0, 1].plot(top_best_history.history['recall'], label='Training Recall')\n",
    "if 'val_recall' in top_best_history.history:\n",
    "    axes[0, 1].plot(top_best_history.history['val_recall'], label='Validation Recall')\n",
    "axes[0, 1].set_title('Model Recall (Best Recall Fold)')\n",
    "axes[0, 1].set_xlabel('Epochs')\n",
    "axes[0, 1].set_ylabel('Recall')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "if 'lr' in top_best_history.history:\n",
    "    axes[1, 0].plot(top_best_history.history['lr'], label='Learning Rate')\n",
    "elif 'learning_rate' in top_best_history.history:\n",
    "    axes[1, 0].plot(top_best_history.history['learning_rate'], label='Learning Rate')\n",
    "axes[1, 0].set_title('Learning Rate')\n",
    "axes[1, 0].set_xlabel('Epochs')\n",
    "axes[1, 0].set_ylabel('Learning Rate')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=top_best_cm, display_labels=[\"Normal\", \"Abnormal\"])\n",
    "disp.plot(cmap=plt.cm.Blues, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Confusion Matrix (Best Recall Fold)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ffa1ad-0ae5-4540-b507-9c37584bb427",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model['model'].save(f'../new_model/{Model_name}.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
