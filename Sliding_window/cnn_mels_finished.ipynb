{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e75e7a1-9ddd-4734-8ff9-424dee2dfc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib as plt\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models, layers, Input\n",
    "from keras.layers import Input\n",
    "from keras.metrics import Metric\n",
    "from IPython.display import clear_output\n",
    "from keras.callbacks import ReduceLROnPlateau, Callback\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b995d86-ca8f-4071-ad58-cddd7ffc7d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 7200, 256, 4, 1)\n",
      "(5, 7200)\n",
      "(5, 1800, 256, 4, 1)\n",
      "(5, 1800)\n",
      "(1000, 256, 4, 1)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "DATA_type = 'mels_cnn_1'\n",
    "Model_name = 'cnn_mels_1'\n",
    "Train_data=np.load(f'../make_stored_data/{DATA_type}/Train_data.npy')\n",
    "Train_label=np.load(f'../make_stored_data/{DATA_type}/Train_lebel.npy')\n",
    "Val_data=np.load(f'../make_stored_data/{DATA_type}/Val_data.npy')\n",
    "Val_label=np.load(f'../make_stored_data/{DATA_type}/Val_lebel.npy')\n",
    "Test_data=np.load(f'../make_stored_data/{DATA_type}/Test_data.npy')\n",
    "Test_label=np.load(f'../make_stored_data/{DATA_type}/Test_lebel.npy')\n",
    "print(np.shape(Train_data))\n",
    "print(np.shape(Train_label))\n",
    "print(np.shape(Val_data))\n",
    "print(np.shape(Val_label))\n",
    "print(np.shape(Test_data))\n",
    "print(np.shape(Test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db538c22-b56c-46b3-9699-5c174d4b4cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F2Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f2_score', threshold=0.3, **kwargs):\n",
    "        super(F2Score, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.tp = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.fp = self.add_weight(name='fp', initializer='zeros')\n",
    "        self.fn = self.add_weight(name='fn', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.cast(y_pred > self.threshold, tf.float32)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        self.tp.assign_add(tf.reduce_sum(y_true * y_pred))\n",
    "        self.fp.assign_add(tf.reduce_sum((1 - y_true) * y_pred))\n",
    "        self.fn.assign_add(tf.reduce_sum(y_true * (1 - y_pred)))\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.tp / (self.tp + self.fp + tf.keras.backend.epsilon())\n",
    "        recall = self.tp / (self.tp + self.fn + tf.keras.backend.epsilon())\n",
    "        return 5 * (precision * recall) / (4 * precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.tp.assign(0)\n",
    "        self.fp.assign(0)\n",
    "        self.fn.assign(0)\n",
    "\n",
    "class F2ScoreLogger(Callback):\n",
    "    def __init__(self, validation_data, threshold=0.3):\n",
    "        super().__init__()\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        self.threshold = threshold\n",
    "        self.y_preds = []\n",
    "        self.f2_scores = []\n",
    "        self.recalls = []\n",
    "        self.precisions = []\n",
    "        self.best_weights = None\n",
    "        self.best_f2 = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred_prob = self.model.predict(self.X_val, verbose=0)\n",
    "        y_pred = (y_pred_prob > self.threshold).astype('int32')\n",
    "        recall = recall_score(self.y_val, y_pred)\n",
    "        precision = precision_score(self.y_val, y_pred)\n",
    "        f2 = 5 / ((4 / recall) + (1 / precision)) if recall and precision else 0\n",
    "\n",
    "        self.y_preds.append(y_pred)\n",
    "        self.recalls.append(recall)\n",
    "        self.precisions.append(precision)\n",
    "        self.f2_scores.append(f2)\n",
    "\n",
    "        if f2 > self.best_f2:\n",
    "            self.best_f2 = f2\n",
    "            self.best_weights = self.model.get_weights()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.best_weights is not None:self.model.set_weights(self.best_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8744513c-16e3-476e-92db-44dc9c909fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running config 1/36\n",
      "Config:\n",
      "  Batch Size     : 16\n",
      "  Learning Rate  : 0.0001\n",
      "  Hidden Units   : 32\n",
      "  Dropout Rate   : 0.05\n",
      "  Kernel Reg L2  : 0.01\n",
      "----------------------------------------\n",
      "Fold : 2\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.9144 - f2_score: 0.8573 - val_loss: 0.9187 - val_f2_score: 0.8870 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.7689 - f2_score: 0.8884 - val_loss: 0.6935 - val_f2_score: 0.9111 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.6944 - f2_score: 0.8956 - val_loss: 0.6721 - val_f2_score: 0.9017 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.6389 - f2_score: 0.9013 - val_loss: 0.6121 - val_f2_score: 0.9031 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.6044 - f2_score: 0.9056 - val_loss: 0.5776 - val_f2_score: 0.9128 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.5669 - f2_score: 0.9089 - val_loss: 0.5504 - val_f2_score: 0.9091 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.5362 - f2_score: 0.9071 - val_loss: 0.5349 - val_f2_score: 0.9110 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 2s 6ms/step - loss: 0.5114 - f2_score: 0.9109 - val_loss: 0.5135 - val_f2_score: 0.9178 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.4869 - f2_score: 0.9132 - val_loss: 0.5047 - val_f2_score: 0.9164 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.4664 - f2_score: 0.9190 - val_loss: 0.4779 - val_f2_score: 0.9232 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 2s 6ms/step - loss: 0.4447 - f2_score: 0.9220 - val_loss: 0.4760 - val_f2_score: 0.9172 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.4291 - f2_score: 0.9195 - val_loss: 0.4761 - val_f2_score: 0.9055 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.4130 - f2_score: 0.9245 - val_loss: 0.4627 - val_f2_score: 0.9114 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.4002 - f2_score: 0.9255 - val_loss: 0.4602 - val_f2_score: 0.9190 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.3868 - f2_score: 0.9292 - val_loss: 0.4521 - val_f2_score: 0.9220 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.3746 - f2_score: 0.9274 - val_loss: 0.4510 - val_f2_score: 0.9281 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.3573 - f2_score: 0.9310 - val_loss: 0.4416 - val_f2_score: 0.9125 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.3449 - f2_score: 0.9351 - val_loss: 0.4392 - val_f2_score: 0.9096 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.3331 - f2_score: 0.9366 - val_loss: 0.4314 - val_f2_score: 0.9116 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.3216 - f2_score: 0.9385 - val_loss: 0.4461 - val_f2_score: 0.9142 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.3108 - f2_score: 0.9414 - val_loss: 0.4382 - val_f2_score: 0.9154 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.3009 - f2_score: 0.9416 - val_loss: 0.4217 - val_f2_score: 0.9144 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.2895 - f2_score: 0.9441 - val_loss: 0.4244 - val_f2_score: 0.9097 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.2814 - f2_score: 0.9446 - val_loss: 0.4391 - val_f2_score: 0.9033 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.2668 - f2_score: 0.9509 - val_loss: 0.4425 - val_f2_score: 0.8915 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.2627 - f2_score: 0.9498 - val_loss: 0.4785 - val_f2_score: 0.8728 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.2536 - f2_score: 0.9531 - val_loss: 0.4450 - val_f2_score: 0.9014 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "375/450 [========================>.....] - ETA: 0s - loss: 0.2301 - f2_score: 0.9606"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"grid_search_outputs\", exist_ok=True)\n",
    "\n",
    "batch_sizes = [16]\n",
    "learning_rates = [0.0001, 0.0005, 0.001]\n",
    "hidden_units = [32, 64, 128]\n",
    "dropouts = [0.05, 0.1]\n",
    "kernel_regs = [0.01, 0.02]\n",
    "\n",
    "param_combinations = list(itertools.product(batch_sizes, learning_rates, hidden_units, dropouts, kernel_regs))\n",
    "\n",
    "results = []\n",
    "best_model = None\n",
    "best_model_config_id = None\n",
    "best_model_f2 = 0\n",
    "\n",
    "for i, (batch_size, lr, hidden_size, dropout_rate, kernel_reg) in enumerate(param_combinations):\n",
    "    fold_recalls = []\n",
    "    fold_f2_scores = []\n",
    "    fold_histories = []\n",
    "    fold_conf_matrices = []\n",
    "\n",
    "    for fold in range(5):\n",
    "        print(f\"Running config {i+1}/{len(param_combinations)}\")\n",
    "        print(\"Config:\")\n",
    "        print(f\"  Batch Size     : {batch_size}\")\n",
    "        print(f\"  Learning Rate  : {lr}\")\n",
    "        print(f\"  Hidden Units   : {hidden_size}\")\n",
    "        print(f\"  Dropout Rate   : {dropout_rate}\")\n",
    "        print(f\"  Kernel Reg L2  : {kernel_reg}\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Fold : {fold+1}\")\n",
    "\n",
    "        X_train, X_val = Train_data[fold], Val_data[fold]\n",
    "        y_train, y_val = Train_label[fold], Val_label[fold]\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        model = models.Sequential([\n",
    "            Input(shape=np.shape(Train_data[0][0])),\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(kernel_reg)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(kernel_reg)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(hidden_size, activation='relu'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=[F2Score(name='f2_score')])\n",
    "        \n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=0)\n",
    "        f2_logger = F2ScoreLogger(validation_data=(X_val, y_val), threshold=0.3)\n",
    "\n",
    "        history = model.fit(X_train, y_train,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                            epochs=100,\n",
    "                            batch_size=batch_size,\n",
    "                            callbacks=[reduce_lr, f2_logger],\n",
    "                            verbose=1)\n",
    "\n",
    "        best_f2 = max(f2_logger.f2_scores)\n",
    "        best_recall = f2_logger.recalls[np.argmax(f2_logger.f2_scores)]\n",
    "        best_epoch = int(np.argmax(f2_logger.f2_scores))\n",
    "        y_pred = f2_logger.y_preds[best_epoch]\n",
    "        cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "        fold_recalls.append(best_recall)\n",
    "        fold_f2_scores.append(best_f2)\n",
    "        fold_histories.append(history)\n",
    "        fold_conf_matrices.append((cm, y_val, y_pred))\n",
    "        \n",
    "        clear_output(wait=False)\n",
    "\n",
    "    best_fold = int(np.argmax(fold_f2_scores))\n",
    "    avg_f2 = np.mean(fold_f2_scores)\n",
    "    avg_recall = np.mean(fold_recalls)\n",
    "\n",
    "    best_history = fold_histories[best_fold]\n",
    "    best_cm, best_y_val, best_y_pred = fold_conf_matrices[best_fold]\n",
    "\n",
    "    results.append({\n",
    "        'config_id': i,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': lr,\n",
    "        'hidden_size': hidden_size,\n",
    "        'dropout': dropout_rate,\n",
    "        'kernel_reg': kernel_reg,\n",
    "        'avg_val_recall': avg_recall,\n",
    "        'best_recall': fold_recalls[best_fold],\n",
    "        'avg_val_f2': avg_f2,\n",
    "        'best_f2': fold_f2_scores[best_fold],\n",
    "        'history': best_history,\n",
    "        'confusion_matrix': best_cm\n",
    "    })\n",
    "\n",
    "    if fold_f2_scores[best_fold] > best_model_f2:\n",
    "        best_model_f2 = fold_f2_scores[best_fold]\n",
    "        best_model_config_id = i\n",
    "        best_model = {\n",
    "            'history': best_history,\n",
    "            'confusion_matrix': best_cm,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5477322a-ee50-4fdf-ae92-450ac514676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results[best_model_config_id]\n",
    "\n",
    "print(\"Best Model Metric\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Config ID             : {best_model_config_id}\")\n",
    "print(f\"Batch Size            : {best_result['batch_size']}\")\n",
    "print(f\"Learning Rate         : {best_result['learning_rate']}\")\n",
    "print(f\"Hidden Units          : {best_result['hidden_size']}\")\n",
    "print(f\"Dropout Rate          : {best_result['dropout']}\")\n",
    "print(f\"Kernel Reg L2         : {best_result['kernel_reg']}\")\n",
    "print(f\"Avg Recall (5-fold)   : {best_result['avg_val_recall']:.4f}\")\n",
    "print(f\"Best Fold Recall      : {best_result['best_recall']:.4f}\")\n",
    "print(f\"Avg F2-score (5-fold) : {best_result['avg_val_f2']:.4f}\")\n",
    "print(f\"Best Fold F2-score    : {best_result['best_f2']:.4f}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "best_history = best_model['history']\n",
    "best_cm = best_model['confusion_matrix']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].plot(best_history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in best_history.history:\n",
    "    axes[0, 0].plot(best_history.history['val_loss'], label='Validation Loss')\n",
    "axes[0, 0].set_title('Model Loss')\n",
    "axes[0, 0].set_xlabel('Epochs')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "if 'f2_score' in best_history.history:\n",
    "    axes[0, 1].plot(best_history.history['f2_score'], label='Training F2 Score')\n",
    "if 'val_f2_score' in best_history.history:\n",
    "    axes[0, 1].plot(best_history.history['val_f2_score'], label='Validation F2 Score')\n",
    "axes[0, 1].set_title('Model F2 Score')\n",
    "axes[0, 1].set_xlabel('Epochs')\n",
    "axes[0, 1].set_ylabel('F2 Score')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "if 'lr' in best_history.history:\n",
    "    axes[1, 0].plot(best_history.history['lr'], label='Learning Rate')\n",
    "elif 'learning_rate' in best_history.history:\n",
    "    axes[1, 0].plot(best_history.history['learning_rate'], label='Learning Rate')\n",
    "axes[1, 0].set_title('Learning Rate')\n",
    "axes[1, 0].set_xlabel('Epochs')\n",
    "axes[1, 0].set_ylabel('Learning Rate')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=best_cm, display_labels=[\"Normal\", \"Abnormal\"])\n",
    "disp.plot(cmap=plt.cm.Blues, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Best Model Confusion Matrix (Validation)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724891ed-f772-482b-ab27-8307073ce909",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(f2_logger.best_weights)\n",
    "Test_pred = (model.predict(Test_data) > 0.3).astype(\"int32\")\n",
    "\n",
    "Test_acc = accuracy_score(Test_label, Test_pred)\n",
    "Test_precision = precision_score(Test_label, Test_pred)\n",
    "Test_recall = recall_score(Test_label, Test_pred)\n",
    "Test_f2 = 5 / ((4 / Test_recall) + (1 / Test_precision)) if recall and precision else 0\n",
    "Test_cm = confusion_matrix(Test_label, Test_pred)\n",
    "\n",
    "print(\"=== Test Set Performance ===\")\n",
    "print(f\"Accuracy  : {Test_acc:.4f}\")\n",
    "print(f\"Precision : {Test_precision:.4f}\")\n",
    "print(f\"Recall    : {Test_recall:.4f}\")\n",
    "print(f\"F2 Score  : {Test_f2:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=Test_cm, display_labels=[\"Normal\", \"Abnormal\"])\n",
    "disp.plot(cmap=plt.cm.Blues, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Best Model Confusion Matrix (Test)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b5823-1dbf-4e24-9019-7ca6399e8b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'../new_model/{Model_name}.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
