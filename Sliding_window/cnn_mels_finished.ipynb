{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e75e7a1-9ddd-4734-8ff9-424dee2dfc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib as plt\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models, layers, Input\n",
    "from keras.layers import Input\n",
    "from keras.metrics import Metric\n",
    "from IPython.display import clear_output\n",
    "from keras.callbacks import ReduceLROnPlateau, Callback\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b995d86-ca8f-4071-ad58-cddd7ffc7d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 7200, 256, 4, 1)\n",
      "(5, 7200)\n",
      "(5, 1800, 256, 4, 1)\n",
      "(5, 1800)\n",
      "(1000, 256, 4, 1)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "DATA_type = 'mels_cnn_1'\n",
    "Model_name = 'cnn_mels_1'\n",
    "Train_data=np.load(f'../make_stored_data/{DATA_type}/Train_data.npy')\n",
    "Train_label=np.load(f'../make_stored_data/{DATA_type}/Train_label.npy')\n",
    "Val_data=np.load(f'../make_stored_data/{DATA_type}/Val_data.npy')\n",
    "Val_label=np.load(f'../make_stored_data/{DATA_type}/Val_label.npy')\n",
    "Test_data=np.load(f'../make_stored_data/{DATA_type}/Test_data.npy')\n",
    "Test_label=np.load(f'../make_stored_data/{DATA_type}/Test_label.npy')\n",
    "print(np.shape(Train_data))\n",
    "print(np.shape(Train_label))\n",
    "print(np.shape(Val_data))\n",
    "print(np.shape(Val_label))\n",
    "print(np.shape(Test_data))\n",
    "print(np.shape(Test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db538c22-b56c-46b3-9699-5c174d4b4cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F2Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f2_score', threshold=0.3, **kwargs):\n",
    "        super(F2Score, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.tp = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.fp = self.add_weight(name='fp', initializer='zeros')\n",
    "        self.fn = self.add_weight(name='fn', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.cast(y_pred > self.threshold, tf.float32)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        self.tp.assign_add(tf.reduce_sum(y_true * y_pred))\n",
    "        self.fp.assign_add(tf.reduce_sum((1 - y_true) * y_pred))\n",
    "        self.fn.assign_add(tf.reduce_sum(y_true * (1 - y_pred)))\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.tp / (self.tp + self.fp + tf.keras.backend.epsilon())\n",
    "        recall = self.tp / (self.tp + self.fn + tf.keras.backend.epsilon())\n",
    "        return 5 * (precision * recall) / (4 * precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.tp.assign(0)\n",
    "        self.fp.assign(0)\n",
    "        self.fn.assign(0)\n",
    "\n",
    "class F2ScoreLogger(Callback):\n",
    "    def __init__(self, validation_data, threshold=0.3):\n",
    "        super().__init__()\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        self.threshold = threshold\n",
    "        self.y_preds = []\n",
    "        self.f2_scores = []\n",
    "        self.recalls = []\n",
    "        self.precisions = []\n",
    "        self.best_weights = None\n",
    "        self.best_f2 = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred_prob = self.model.predict(self.X_val, verbose=0)\n",
    "        y_pred = (y_pred_prob > self.threshold).astype('int32')\n",
    "        recall = recall_score(self.y_val, y_pred)\n",
    "        precision = precision_score(self.y_val, y_pred)\n",
    "        f2 = 5 / ((4 / recall) + (1 / precision)) if recall and precision else 0\n",
    "\n",
    "        self.y_preds.append(y_pred)\n",
    "        self.recalls.append(recall)\n",
    "        self.precisions.append(precision)\n",
    "        self.f2_scores.append(f2)\n",
    "\n",
    "        if f2 > self.best_f2:\n",
    "            self.best_f2 = f2\n",
    "            self.best_weights = self.model.get_weights()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.best_weights is not None:self.model.set_weights(self.best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8744513c-16e3-476e-92db-44dc9c909fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running config 1/36\n",
      "Config:\n",
      "  Batch Size     : 16\n",
      "  Learning Rate  : 0.0001\n",
      "  Hidden Units   : 32\n",
      "  Dropout Rate   : 0.05\n",
      "  Kernel Reg L2  : 0.01\n",
      "----------------------------------------\n",
      "Fold : 1\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 13s 14ms/step - loss: 0.9136 - f2_score: 0.8457 - val_loss: 0.9044 - val_f2_score: 0.8835 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 5s 12ms/step - loss: 0.7484 - f2_score: 0.8843 - val_loss: 0.7105 - val_f2_score: 0.8840 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 6s 12ms/step - loss: 0.6699 - f2_score: 0.8985 - val_loss: 0.6744 - val_f2_score: 0.8565 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.6206 - f2_score: 0.9021 - val_loss: 0.6340 - val_f2_score: 0.9012 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 5s 12ms/step - loss: 0.5814 - f2_score: 0.9073 - val_loss: 0.6079 - val_f2_score: 0.8724 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 6s 12ms/step - loss: 0.5495 - f2_score: 0.9100 - val_loss: 0.5832 - val_f2_score: 0.8826 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 5s 12ms/step - loss: 0.5176 - f2_score: 0.9135 - val_loss: 0.5576 - val_f2_score: 0.9098 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 6s 12ms/step - loss: 0.4904 - f2_score: 0.9195 - val_loss: 0.5313 - val_f2_score: 0.9002 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 5s 12ms/step - loss: 0.4755 - f2_score: 0.9171 - val_loss: 0.5263 - val_f2_score: 0.9025 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.4586 - f2_score: 0.9170 - val_loss: 0.5051 - val_f2_score: 0.9023 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.4327 - f2_score: 0.9230 - val_loss: 0.5069 - val_f2_score: 0.9107 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.4233 - f2_score: 0.9226 - val_loss: 0.4975 - val_f2_score: 0.8943 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.4032 - f2_score: 0.9273 - val_loss: 0.4879 - val_f2_score: 0.9115 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 6s 12ms/step - loss: 0.3870 - f2_score: 0.9290 - val_loss: 0.4770 - val_f2_score: 0.9105 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.3793 - f2_score: 0.9284 - val_loss: 0.4942 - val_f2_score: 0.8933 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 6s 12ms/step - loss: 0.3645 - f2_score: 0.9311 - val_loss: 0.4563 - val_f2_score: 0.9025 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 6s 12ms/step - loss: 0.3489 - f2_score: 0.9340 - val_loss: 0.4860 - val_f2_score: 0.9129 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.3384 - f2_score: 0.9367 - val_loss: 0.4729 - val_f2_score: 0.9081 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.3235 - f2_score: 0.9392 - val_loss: 0.4572 - val_f2_score: 0.9041 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.3153 - f2_score: 0.9414 - val_loss: 0.4657 - val_f2_score: 0.8855 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.3003 - f2_score: 0.9417 - val_loss: 0.4870 - val_f2_score: 0.8703 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2811 - f2_score: 0.9470 - val_loss: 0.4540 - val_f2_score: 0.9096 - lr: 2.0000e-05\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 5s 12ms/step - loss: 0.2769 - f2_score: 0.9504 - val_loss: 0.4474 - val_f2_score: 0.9009 - lr: 2.0000e-05\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 5s 12ms/step - loss: 0.2758 - f2_score: 0.9506 - val_loss: 0.4455 - val_f2_score: 0.9039 - lr: 2.0000e-05\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2692 - f2_score: 0.9502 - val_loss: 0.4520 - val_f2_score: 0.9019 - lr: 2.0000e-05\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2699 - f2_score: 0.9518 - val_loss: 0.4537 - val_f2_score: 0.9038 - lr: 2.0000e-05\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2617 - f2_score: 0.9512 - val_loss: 0.4514 - val_f2_score: 0.9048 - lr: 2.0000e-05\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2636 - f2_score: 0.9498 - val_loss: 0.4497 - val_f2_score: 0.9062 - lr: 2.0000e-05\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2576 - f2_score: 0.9550 - val_loss: 0.4485 - val_f2_score: 0.9015 - lr: 2.0000e-05\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2526 - f2_score: 0.9554 - val_loss: 0.4495 - val_f2_score: 0.9017 - lr: 4.0000e-06\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 6s 12ms/step - loss: 0.2513 - f2_score: 0.9545 - val_loss: 0.4497 - val_f2_score: 0.9027 - lr: 4.0000e-06\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2504 - f2_score: 0.9531 - val_loss: 0.4493 - val_f2_score: 0.9031 - lr: 4.0000e-06\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2505 - f2_score: 0.9569 - val_loss: 0.4506 - val_f2_score: 0.9028 - lr: 4.0000e-06\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2501 - f2_score: 0.9584 - val_loss: 0.4500 - val_f2_score: 0.9059 - lr: 4.0000e-06\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2511 - f2_score: 0.9549 - val_loss: 0.4502 - val_f2_score: 0.9076 - lr: 1.0000e-06\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2492 - f2_score: 0.9568 - val_loss: 0.4487 - val_f2_score: 0.9034 - lr: 1.0000e-06\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 6s 12ms/step - loss: 0.2496 - f2_score: 0.9566 - val_loss: 0.4490 - val_f2_score: 0.9050 - lr: 1.0000e-06\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2488 - f2_score: 0.9568 - val_loss: 0.4500 - val_f2_score: 0.9050 - lr: 1.0000e-06\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2478 - f2_score: 0.9555 - val_loss: 0.4494 - val_f2_score: 0.9059 - lr: 1.0000e-06\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2481 - f2_score: 0.9560 - val_loss: 0.4503 - val_f2_score: 0.9059 - lr: 1.0000e-06\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2491 - f2_score: 0.9560 - val_loss: 0.4497 - val_f2_score: 0.9050 - lr: 1.0000e-06\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2477 - f2_score: 0.9584 - val_loss: 0.4497 - val_f2_score: 0.9050 - lr: 1.0000e-06\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2501 - f2_score: 0.9553 - val_loss: 0.4488 - val_f2_score: 0.9001 - lr: 1.0000e-06\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2474 - f2_score: 0.9577 - val_loss: 0.4495 - val_f2_score: 0.9003 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 6s 12ms/step - loss: 0.2455 - f2_score: 0.9582 - val_loss: 0.4498 - val_f2_score: 0.8992 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2478 - f2_score: 0.9549 - val_loss: 0.4500 - val_f2_score: 0.9031 - lr: 1.0000e-06\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2472 - f2_score: 0.9558 - val_loss: 0.4503 - val_f2_score: 0.9031 - lr: 1.0000e-06\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2501 - f2_score: 0.9570 - val_loss: 0.4500 - val_f2_score: 0.9039 - lr: 1.0000e-06\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 6s 12ms/step - loss: 0.2496 - f2_score: 0.9542 - val_loss: 0.4502 - val_f2_score: 0.9064 - lr: 1.0000e-06\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 6s 12ms/step - loss: 0.2465 - f2_score: 0.9566 - val_loss: 0.4491 - val_f2_score: 0.9039 - lr: 1.0000e-06\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2418 - f2_score: 0.9562 - val_loss: 0.4499 - val_f2_score: 0.9052 - lr: 1.0000e-06\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2474 - f2_score: 0.9561 - val_loss: 0.4494 - val_f2_score: 0.9041 - lr: 1.0000e-06\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2458 - f2_score: 0.9563 - val_loss: 0.4492 - val_f2_score: 0.9048 - lr: 1.0000e-06\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2463 - f2_score: 0.9564 - val_loss: 0.4489 - val_f2_score: 0.9050 - lr: 1.0000e-06\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2421 - f2_score: 0.9585 - val_loss: 0.4502 - val_f2_score: 0.9048 - lr: 1.0000e-06\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2448 - f2_score: 0.9563 - val_loss: 0.4502 - val_f2_score: 0.9041 - lr: 1.0000e-06\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2505 - f2_score: 0.9555 - val_loss: 0.4498 - val_f2_score: 0.9036 - lr: 1.0000e-06\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2428 - f2_score: 0.9551 - val_loss: 0.4497 - val_f2_score: 0.9045 - lr: 1.0000e-06\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 6s 12ms/step - loss: 0.2460 - f2_score: 0.9562 - val_loss: 0.4502 - val_f2_score: 0.9048 - lr: 1.0000e-06\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2454 - f2_score: 0.9587 - val_loss: 0.4502 - val_f2_score: 0.9048 - lr: 1.0000e-06\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2445 - f2_score: 0.9580 - val_loss: 0.4503 - val_f2_score: 0.9057 - lr: 1.0000e-06\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2426 - f2_score: 0.9579 - val_loss: 0.4493 - val_f2_score: 0.9052 - lr: 1.0000e-06\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2446 - f2_score: 0.9557 - val_loss: 0.4495 - val_f2_score: 0.9024 - lr: 1.0000e-06\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 6s 14ms/step - loss: 0.2417 - f2_score: 0.9594 - val_loss: 0.4501 - val_f2_score: 0.9048 - lr: 1.0000e-06\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 6s 14ms/step - loss: 0.2442 - f2_score: 0.9567 - val_loss: 0.4507 - val_f2_score: 0.9046 - lr: 1.0000e-06\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2451 - f2_score: 0.9593 - val_loss: 0.4495 - val_f2_score: 0.9039 - lr: 1.0000e-06\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2456 - f2_score: 0.9562 - val_loss: 0.4491 - val_f2_score: 0.9050 - lr: 1.0000e-06\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 6s 12ms/step - loss: 0.2434 - f2_score: 0.9570 - val_loss: 0.4492 - val_f2_score: 0.9048 - lr: 1.0000e-06\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 6s 12ms/step - loss: 0.2429 - f2_score: 0.9572 - val_loss: 0.4497 - val_f2_score: 0.9055 - lr: 1.0000e-06\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2419 - f2_score: 0.9558 - val_loss: 0.4496 - val_f2_score: 0.9053 - lr: 1.0000e-06\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2432 - f2_score: 0.9584 - val_loss: 0.4493 - val_f2_score: 0.9046 - lr: 1.0000e-06\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 6s 12ms/step - loss: 0.2425 - f2_score: 0.9547 - val_loss: 0.4498 - val_f2_score: 0.9055 - lr: 1.0000e-06\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2426 - f2_score: 0.9574 - val_loss: 0.4502 - val_f2_score: 0.9046 - lr: 1.0000e-06\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2436 - f2_score: 0.9595 - val_loss: 0.4490 - val_f2_score: 0.9051 - lr: 1.0000e-06\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2465 - f2_score: 0.9558 - val_loss: 0.4489 - val_f2_score: 0.9053 - lr: 1.0000e-06\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2441 - f2_score: 0.9588 - val_loss: 0.4484 - val_f2_score: 0.9039 - lr: 1.0000e-06\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 6s 13ms/step - loss: 0.2435 - f2_score: 0.9580 - val_loss: 0.4496 - val_f2_score: 0.9053 - lr: 1.0000e-06\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 6s 12ms/step - loss: 0.2446 - f2_score: 0.9544 - val_loss: 0.4493 - val_f2_score: 0.9051 - lr: 1.0000e-06\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 5s 12ms/step - loss: 0.2424 - f2_score: 0.9562 - val_loss: 0.4490 - val_f2_score: 0.9053 - lr: 1.0000e-06\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 5s 12ms/step - loss: 0.2487 - f2_score: 0.9569 - val_loss: 0.4486 - val_f2_score: 0.9053 - lr: 1.0000e-06\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 5s 12ms/step - loss: 0.2407 - f2_score: 0.9591 - val_loss: 0.4490 - val_f2_score: 0.9055 - lr: 1.0000e-06\n",
      "Epoch 82/100\n",
      "400/450 [=========================>....] - ETA: 0s - loss: 0.2436 - f2_score: 0.9573"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"grid_search_outputs\", exist_ok=True)\n",
    "\n",
    "batch_sizes = [16]\n",
    "learning_rates = [0.0001, 0.0005]\n",
    "hidden_units = [32, 64]\n",
    "dropouts = [0.05, 0.1]\n",
    "kernel_regs = [0.01, 0.02]\n",
    "\n",
    "param_combinations = list(itertools.product(batch_sizes, learning_rates, hidden_units, dropouts, kernel_regs))\n",
    "\n",
    "results = []\n",
    "best_model = None\n",
    "best_model_config_id = None\n",
    "best_model_f2 = 0\n",
    "\n",
    "for i, (batch_size, lr, hidden_size, dropout_rate, kernel_reg) in enumerate(param_combinations):\n",
    "    fold_recalls = []\n",
    "    fold_f2_scores = []\n",
    "    fold_histories = []\n",
    "    fold_conf_matrices = []\n",
    "\n",
    "    for fold in range(5):\n",
    "        print(f\"Running config {i+1}/{len(param_combinations)}\")\n",
    "        print(\"Config:\")\n",
    "        print(f\"  Batch Size     : {batch_size}\")\n",
    "        print(f\"  Learning Rate  : {lr}\")\n",
    "        print(f\"  Hidden Units   : {hidden_size}\")\n",
    "        print(f\"  Dropout Rate   : {dropout_rate}\")\n",
    "        print(f\"  Kernel Reg L2  : {kernel_reg}\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Fold : {fold+1}\")\n",
    "\n",
    "        X_train, X_val = Train_data[fold], Val_data[fold]\n",
    "        y_train, y_val = Train_label[fold], Val_label[fold]\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        model = models.Sequential([\n",
    "            Input(shape=np.shape(Train_data[0][0])),\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(kernel_reg)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(kernel_reg)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(hidden_size, activation='relu'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=[F2Score(name='f2_score')])\n",
    "        \n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=0)\n",
    "        f2_logger = F2ScoreLogger(validation_data=(X_val, y_val), threshold=0.3)\n",
    "\n",
    "        history = model.fit(X_train, y_train,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                            epochs=100,\n",
    "                            batch_size=batch_size,\n",
    "                            callbacks=[reduce_lr, f2_logger],\n",
    "                            verbose=1)\n",
    "\n",
    "        best_f2 = max(f2_logger.f2_scores)\n",
    "        best_recall = f2_logger.recalls[np.argmax(f2_logger.f2_scores)]\n",
    "        best_epoch = int(np.argmax(f2_logger.f2_scores))\n",
    "        y_pred = f2_logger.y_preds[best_epoch]\n",
    "        cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "        fold_recalls.append(best_recall)\n",
    "        fold_f2_scores.append(best_f2)\n",
    "        fold_histories.append(history)\n",
    "        fold_conf_matrices.append((cm, y_val, y_pred))\n",
    "        \n",
    "        clear_output(wait=False)\n",
    "\n",
    "    best_fold = int(np.argmax(fold_f2_scores))\n",
    "    avg_f2 = np.mean(fold_f2_scores)\n",
    "    avg_recall = np.mean(fold_recalls)\n",
    "\n",
    "    best_history = fold_histories[best_fold]\n",
    "    best_cm, best_y_val, best_y_pred = fold_conf_matrices[best_fold]\n",
    "\n",
    "    results.append({\n",
    "        'config_id': i,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': lr,\n",
    "        'hidden_size': hidden_size,\n",
    "        'dropout': dropout_rate,\n",
    "        'kernel_reg': kernel_reg,\n",
    "        'avg_val_recall': avg_recall,\n",
    "        'best_recall': fold_recalls[best_fold],\n",
    "        'avg_val_f2': avg_f2,\n",
    "        'best_f2': fold_f2_scores[best_fold],\n",
    "        'history': best_history,\n",
    "        'confusion_matrix': best_cm\n",
    "    })\n",
    "\n",
    "    if fold_f2_scores[best_fold] > best_model_f2:\n",
    "        best_model_f2 = fold_f2_scores[best_fold]\n",
    "        best_model_config_id = i\n",
    "        best_model = {\n",
    "            'history': best_history,\n",
    "            'confusion_matrix': best_cm,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5477322a-ee50-4fdf-ae92-450ac514676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results[best_model_config_id]\n",
    "\n",
    "print(\"Best Model Metric\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Config ID             : {best_model_config_id}\")\n",
    "print(f\"Batch Size            : {best_result['batch_size']}\")\n",
    "print(f\"Learning Rate         : {best_result['learning_rate']}\")\n",
    "print(f\"Hidden Units          : {best_result['hidden_size']}\")\n",
    "print(f\"Dropout Rate          : {best_result['dropout']}\")\n",
    "print(f\"Kernel Reg L2         : {best_result['kernel_reg']}\")\n",
    "print(f\"Avg Recall (5-fold)   : {best_result['avg_val_recall']:.4f}\")\n",
    "print(f\"Best Fold Recall      : {best_result['best_recall']:.4f}\")\n",
    "print(f\"Avg F2-score (5-fold) : {best_result['avg_val_f2']:.4f}\")\n",
    "print(f\"Best Fold F2-score    : {best_result['best_f2']:.4f}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "best_history = best_model['history']\n",
    "best_cm = best_model['confusion_matrix']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].plot(best_history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in best_history.history:\n",
    "    axes[0, 0].plot(best_history.history['val_loss'], label='Validation Loss')\n",
    "axes[0, 0].set_title('Model Loss')\n",
    "axes[0, 0].set_xlabel('Epochs')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "if 'f2_score' in best_history.history:\n",
    "    axes[0, 1].plot(best_history.history['f2_score'], label='Training F2 Score')\n",
    "if 'val_f2_score' in best_history.history:\n",
    "    axes[0, 1].plot(best_history.history['val_f2_score'], label='Validation F2 Score')\n",
    "axes[0, 1].set_title('Model F2 Score')\n",
    "axes[0, 1].set_xlabel('Epochs')\n",
    "axes[0, 1].set_ylabel('F2 Score')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "if 'lr' in best_history.history:\n",
    "    axes[1, 0].plot(best_history.history['lr'], label='Learning Rate')\n",
    "elif 'learning_rate' in best_history.history:\n",
    "    axes[1, 0].plot(best_history.history['learning_rate'], label='Learning Rate')\n",
    "axes[1, 0].set_title('Learning Rate')\n",
    "axes[1, 0].set_xlabel('Epochs')\n",
    "axes[1, 0].set_ylabel('Learning Rate')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=best_cm, display_labels=[\"Normal\", \"Abnormal\"])\n",
    "disp.plot(cmap=plt.cm.Blues, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Best Model Confusion Matrix (Validation)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724891ed-f772-482b-ab27-8307073ce909",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(f2_logger.best_weights)\n",
    "Test_pred = (model.predict(Test_data) > 0.3).astype(\"int32\")\n",
    "\n",
    "Test_acc = accuracy_score(Test_label, Test_pred)\n",
    "Test_precision = precision_score(Test_label, Test_pred)\n",
    "Test_recall = recall_score(Test_label, Test_pred)\n",
    "Test_f2 = 5 / ((4 / Test_recall) + (1 / Test_precision)) if Test_recall and Test_precision else 0\n",
    "Test_cm = confusion_matrix(Test_label, Test_pred)\n",
    "\n",
    "print(\"=== Test Set Performance ===\")\n",
    "print(f\"Accuracy  : {Test_acc:.4f}\")\n",
    "print(f\"Precision : {Test_precision:.4f}\")\n",
    "print(f\"Recall    : {Test_recall:.4f}\")\n",
    "print(f\"F2 Score  : {Test_f2:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "Test_disp = ConfusionMatrixDisplay(confusion_matrix=Test_cm, display_labels=[\"Normal\", \"Abnormal\"])\n",
    "Test_disp.plot(cmap=plt.cm.Blues, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Best Model Confusion Matrix (Test)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b5823-1dbf-4e24-9019-7ca6399e8b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'../new_model/{Model_name}.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
