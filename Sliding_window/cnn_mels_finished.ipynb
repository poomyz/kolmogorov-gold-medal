{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e75e7a1-9ddd-4734-8ff9-424dee2dfc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib as plt\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models, layers, Input\n",
    "from keras.layers import Input\n",
    "from keras.metrics import Metric\n",
    "from IPython.display import clear_output\n",
    "from keras.callbacks import ReduceLROnPlateau, Callback\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b995d86-ca8f-4071-ad58-cddd7ffc7d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_type = 'mels_cnn_1'\n",
    "Model_name = 'cnn_mels_1'\n",
    "Train_data=np.load(f'../make_stored_data/{DATA_type}/Train_data.npy')\n",
    "Train_label=np.load(f'../make_stored_data/{DATA_type}/Train_lebel.npy')\n",
    "Val_data=np.load(f'../make_stored_data/{DATA_type}/Val_data.npy')\n",
    "Val_label=np.load(f'../make_stored_data/{DATA_type}/Val_lebel.npy')\n",
    "print(np.shape(Train_data))\n",
    "print(np.shape(Train_label))\n",
    "print(np.shape(Val_data))\n",
    "print(np.shape(Val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db538c22-b56c-46b3-9699-5c174d4b4cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F2Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f2_score', threshold=0.5, **kwargs):\n",
    "        super(F2Score, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.tp = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.fp = self.add_weight(name='fp', initializer='zeros')\n",
    "        self.fn = self.add_weight(name='fn', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.cast(y_pred > self.threshold, tf.float32)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        self.tp.assign_add(tf.reduce_sum(y_true * y_pred))\n",
    "        self.fp.assign_add(tf.reduce_sum((1 - y_true) * y_pred))\n",
    "        self.fn.assign_add(tf.reduce_sum(y_true * (1 - y_pred)))\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.tp / (self.tp + self.fp + tf.keras.backend.epsilon())\n",
    "        recall = self.tp / (self.tp + self.fn + tf.keras.backend.epsilon())\n",
    "        return 5 * (precision * recall) / (4 * precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.tp.assign(0)\n",
    "        self.fp.assign(0)\n",
    "        self.fn.assign(0)\n",
    "\n",
    "class MemoryBestWeights(Callback):\n",
    "    def __init__(self, monitor='val_f2_score', mode='max'):\n",
    "        super().__init__()\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode == 'min':\n",
    "            self.best = np.Inf\n",
    "            self.monitor_op = np.less\n",
    "        else:\n",
    "            self.best = -np.Inf\n",
    "            self.monitor_op = np.greater\n",
    "\n",
    "        self.best_weights = None\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:return\n",
    "        if self.monitor_op(current, self.best):\n",
    "            self.best = current\n",
    "            try:self.best_weights = self.model.get_weights()\n",
    "            except Exception as e:\n",
    "                print(f\"[Warning] Failed to get weights at epoch {epoch}: {e}\")\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.best_weights is not None:\n",
    "            self.model.set_weights(self.best_weights)\n",
    "            print(f\"Restored best weights from {self.monitor} = {self.best:.4f}\")\n",
    "        else:print(\"No improvement was tracked; model weights not restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8744513c-16e3-476e-92db-44dc9c909fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_f2 = 0\n",
    "def custom_f2(recall, precision):\n",
    "    if recall == 0 or precision == 0:\n",
    "        return 0\n",
    "    return 5 / ((4 / recall) + (1 / precision))\n",
    "\n",
    "os.makedirs(\"grid_search_outputs\", exist_ok=True)\n",
    "\n",
    "batch_sizes = [16]\n",
    "learning_rates = [0.0001, 0.0005, 0.001]\n",
    "hidden_units = [32, 64, 128]\n",
    "dropouts = [0.05, 0.1]\n",
    "kernel_regs = [0.01, 0.02]\n",
    "\n",
    "param_combinations = list(itertools.product(batch_sizes, learning_rates, hidden_units, dropouts, kernel_regs))\n",
    "\n",
    "results = []\n",
    "best_model = None\n",
    "best_model_config_id = None\n",
    "unused_best_model_recall = 0\n",
    "\n",
    "for i, (batch_size, lr, hidden_size, dropout_rate, kernel_reg) in enumerate(param_combinations):\n",
    "    fold_recalls = []\n",
    "    fold_f2_scores = []\n",
    "    fold_histories = []\n",
    "    fold_conf_matrices = []\n",
    "\n",
    "    for fold in range(5):\n",
    "        print(f\"Running config {i+1}/{len(param_combinations)}\")\n",
    "        print(\"Config:\")\n",
    "        print(f\"  Batch Size     : {batch_size}\")\n",
    "        print(f\"  Learning Rate  : {lr}\")\n",
    "        print(f\"  Hidden Units   : {hidden_size}\")\n",
    "        print(f\"  Dropout Rate   : {dropout_rate}\")\n",
    "        print(f\"  Kernel Reg L2  : {kernel_reg}\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Fold : {fold+1}\")\n",
    "        X_train, X_val = Train_data[fold], Val_data[fold]\n",
    "        y_train, y_val = Train_label[fold], Val_label[fold]\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        model = models.Sequential([\n",
    "            Input(shape=np.shape(Train_data[0][0])),\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(kernel_reg)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(kernel_reg)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(hidden_size, activation='relu'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=[F2Score(name='f2_score')])\n",
    "\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=0)\n",
    "        memory_best = MemoryBestWeights(monitor='val_f2_score', mode='max')\n",
    "\n",
    "        history = model.fit(X_train, y_train,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                            epochs=100,\n",
    "                            batch_size=batch_size,\n",
    "                            callbacks=[reduce_lr, memory_best],\n",
    "                            verbose=1)\n",
    "\n",
    "        epoch_recalls = []\n",
    "        epoch_precisions = []\n",
    "        epoch_f2_scores = []\n",
    "        for epoch in range(100):\n",
    "            y_pred = (model.predict(X_val, verbose=0) > 0.3).astype('int32')\n",
    "            recall = recall_score(y_val, y_pred)\n",
    "            precision = precision_score(y_val, y_pred)\n",
    "            f2 = custom_f2(recall, precision)\n",
    "            epoch_recalls.append(recall)\n",
    "            epoch_precisions.append(precision)\n",
    "            epoch_f2_scores.append(f2)\n",
    "\n",
    "        best_epoch = int(np.argmax(epoch_f2_scores))\n",
    "        best_f2 = epoch_f2_scores[best_epoch]\n",
    "        best_recall = epoch_recalls[best_epoch]\n",
    "\n",
    "        fold_recalls.append(best_recall)\n",
    "        fold_f2_scores.append(best_f2)\n",
    "        fold_histories.append(history)\n",
    "        y_pred = (model.predict(X_val, verbose=0) > 0.3).astype(\"int32\")\n",
    "        cm = confusion_matrix(y_val, y_pred)\n",
    "        fold_conf_matrices.append((cm, y_val, y_pred))\n",
    "        \n",
    "        clear_output(wait=False)\n",
    "\n",
    "    best_fold = int(np.argmax(fold_f2_scores))\n",
    "    avg_f2 = np.mean(fold_f2_scores)\n",
    "    avg_recall = np.mean(fold_recalls)\n",
    "\n",
    "    best_history = fold_histories[best_fold]\n",
    "    best_cm, best_y_val, best_y_pred = fold_conf_matrices[best_fold]\n",
    "\n",
    "    results.append({\n",
    "        'config_id': i,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': lr,\n",
    "        'hidden_size': hidden_size,\n",
    "        'dropout': dropout_rate,\n",
    "        'kernel_reg': kernel_reg,\n",
    "        'avg_val_recall': avg_recall,\n",
    "        'best_recall': fold_recalls[best_fold],\n",
    "        'avg_val_f2': avg_f2,\n",
    "        'best_f2': fold_f2_scores[best_fold],\n",
    "        'history': best_history,\n",
    "        'confusion_matrix': best_cm\n",
    "    })\n",
    "\n",
    "    if avg_f2 > best_model_f2:\n",
    "        best_model_f2 = avg_f2\n",
    "        best_model_config_id = i\n",
    "        best_model = {\n",
    "            'history': best_history,\n",
    "            'confusion_matrix': best_cm,\n",
    "            'model': model\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5477322a-ee50-4fdf-ae92-450ac514676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results[best_model_config_id]\n",
    "\n",
    "print(\"Best Model Metric\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Config ID             : {best_model_config_id}\")\n",
    "print(f\"Batch Size            : {best_result['batch_size']}\")\n",
    "print(f\"Learning Rate         : {best_result['learning_rate']}\")\n",
    "print(f\"Hidden Units          : {best_result['hidden_size']}\")\n",
    "print(f\"Dropout Rate          : {best_result['dropout']}\")\n",
    "print(f\"Kernel Reg L2         : {best_result['kernel_reg']}\")\n",
    "print(f\"Avg Recall (5-fold)   : {best_result['avg_val_recall']:.4f}\")\n",
    "print(f\"Best Fold Recall      : {best_result['best_recall']:.4f}\")\n",
    "print(f\"Avg F2-score (5-fold) : {best_result['avg_val_f2']:.4f}\")\n",
    "print(f\"Best Fold F2-score    : {best_result['best_f2']:.4f}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "best_history = best_model['history']\n",
    "best_cm = best_model['confusion_matrix']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].plot(best_history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in best_history.history:\n",
    "    axes[0, 0].plot(best_history.history['val_loss'], label='Validation Loss')\n",
    "axes[0, 0].set_title('Model Loss')\n",
    "axes[0, 0].set_xlabel('Epochs')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "if 'f2_score' in best_history.history:\n",
    "    axes[0, 1].plot(best_history.history['f2_score'], label='Training F2 Score')\n",
    "if 'val_f2_score' in best_history.history:\n",
    "    axes[0, 1].plot(best_history.history['val_f2_score'], label='Validation F2 Score')\n",
    "axes[0, 1].set_title('Model F2 Score')\n",
    "axes[0, 1].set_xlabel('Epochs')\n",
    "axes[0, 1].set_ylabel('F2 Score')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "if 'lr' in best_history.history:\n",
    "    axes[1, 0].plot(best_history.history['lr'], label='Learning Rate')\n",
    "elif 'learning_rate' in best_history.history:\n",
    "    axes[1, 0].plot(best_history.history['learning_rate'], label='Learning Rate')\n",
    "axes[1, 0].set_title('Learning Rate')\n",
    "axes[1, 0].set_xlabel('Epochs')\n",
    "axes[1, 0].set_ylabel('Learning Rate')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=best_cm, display_labels=[\"Normal\", \"Abnormal\"])\n",
    "disp.plot(cmap=plt.cm.Blues, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Best Model Confusion Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b5823-1dbf-4e24-9019-7ca6399e8b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model['model'].save(f'../new_model/{Model_name}.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
