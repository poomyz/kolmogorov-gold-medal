{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e75e7a1-9ddd-4734-8ff9-424dee2dfc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib as plt\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models, layers, Input\n",
    "from keras.layers import Input\n",
    "from keras.metrics import Metric\n",
    "from IPython.display import clear_output\n",
    "from keras.callbacks import ReduceLROnPlateau, Callback\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b995d86-ca8f-4071-ad58-cddd7ffc7d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 7200, 256, 4, 1)\n",
      "(5, 7200)\n",
      "(5, 1800, 256, 4, 1)\n",
      "(5, 1800)\n"
     ]
    }
   ],
   "source": [
    "DATA_type = 'mels_cnn_1'\n",
    "Model_name = 'cnn_mels_1'\n",
    "Train_data=np.load(f'../make_stored_data/{DATA_type}/Train_data.npy')\n",
    "Train_label=np.load(f'../make_stored_data/{DATA_type}/Train_lebel.npy')\n",
    "Val_data=np.load(f'../make_stored_data/{DATA_type}/Val_data.npy')\n",
    "Val_label=np.load(f'../make_stored_data/{DATA_type}/Val_lebel.npy')\n",
    "print(np.shape(Train_data))\n",
    "print(np.shape(Train_label))\n",
    "print(np.shape(Val_data))\n",
    "print(np.shape(Val_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db538c22-b56c-46b3-9699-5c174d4b4cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F2Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f2_score', threshold=0.3, **kwargs):\n",
    "        super(F2Score, self).__init__(name=name, **kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.tp = self.add_weight(name='tp', initializer='zeros')\n",
    "        self.fp = self.add_weight(name='fp', initializer='zeros')\n",
    "        self.fn = self.add_weight(name='fn', initializer='zeros')\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.cast(y_pred > self.threshold, tf.float32)\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        self.tp.assign_add(tf.reduce_sum(y_true * y_pred))\n",
    "        self.fp.assign_add(tf.reduce_sum((1 - y_true) * y_pred))\n",
    "        self.fn.assign_add(tf.reduce_sum(y_true * (1 - y_pred)))\n",
    "\n",
    "    def result(self):\n",
    "        precision = self.tp / (self.tp + self.fp + tf.keras.backend.epsilon())\n",
    "        recall = self.tp / (self.tp + self.fn + tf.keras.backend.epsilon())\n",
    "        return 5 * (precision * recall) / (4 * precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.tp.assign(0)\n",
    "        self.fp.assign(0)\n",
    "        self.fn.assign(0)\n",
    "\n",
    "class F2ScoreLogger(Callback):\n",
    "    def __init__(self, validation_data, threshold=0.3):\n",
    "        super().__init__()\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        self.threshold = threshold\n",
    "        self.y_preds = []\n",
    "        self.f2_scores = []\n",
    "        self.recalls = []\n",
    "        self.precisions = []\n",
    "        self.best_weights = None\n",
    "        self.best_f2 = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        y_pred_prob = self.model.predict(self.X_val, verbose=0)\n",
    "        y_pred = (y_pred_prob > self.threshold).astype('int32')\n",
    "        recall = recall_score(self.y_val, y_pred)\n",
    "        precision = precision_score(self.y_val, y_pred)\n",
    "        f2 = 5 / ((4 / recall) + (1 / precision)) if recall and precision else 0\n",
    "\n",
    "        self.y_preds.append(y_pred)\n",
    "        self.recalls.append(recall)\n",
    "        self.precisions.append(precision)\n",
    "        self.f2_scores.append(f2)\n",
    "\n",
    "        if f2 > self.best_f2:\n",
    "            self.best_f2 = f2\n",
    "            self.best_weights = self.model.get_weights()\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.best_weights is not None:self.model.set_weights(self.best_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8744513c-16e3-476e-92db-44dc9c909fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running config 1/36\n",
      "Config:\n",
      "  Batch Size     : 16\n",
      "  Learning Rate  : 0.0001\n",
      "  Hidden Units   : 32\n",
      "  Dropout Rate   : 0.05\n",
      "  Kernel Reg L2  : 0.01\n",
      "----------------------------------------\n",
      "Fold : 1\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 7s 6ms/step - loss: 0.8918 - f2_score: 0.7792 - val_loss: 0.8708 - val_f2_score: 0.8827 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.7226 - f2_score: 0.8322 - val_loss: 0.6997 - val_f2_score: 0.8308 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.6579 - f2_score: 0.8482 - val_loss: 0.6502 - val_f2_score: 0.8241 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.6053 - f2_score: 0.8580 - val_loss: 0.6067 - val_f2_score: 0.8322 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.5651 - f2_score: 0.8588 - val_loss: 0.5956 - val_f2_score: 0.8512 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.5345 - f2_score: 0.8695 - val_loss: 0.5559 - val_f2_score: 0.8425 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.5059 - f2_score: 0.8680 - val_loss: 0.5322 - val_f2_score: 0.8528 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.4800 - f2_score: 0.8734 - val_loss: 0.5214 - val_f2_score: 0.8244 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.4603 - f2_score: 0.8812 - val_loss: 0.5110 - val_f2_score: 0.7914 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.4453 - f2_score: 0.8788 - val_loss: 0.5015 - val_f2_score: 0.8129 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.4277 - f2_score: 0.8831 - val_loss: 0.4733 - val_f2_score: 0.8644 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.4089 - f2_score: 0.8918 - val_loss: 0.4771 - val_f2_score: 0.8668 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.4016 - f2_score: 0.8877 - val_loss: 0.4657 - val_f2_score: 0.8745 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.3901 - f2_score: 0.8898 - val_loss: 0.4657 - val_f2_score: 0.8727 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.3736 - f2_score: 0.8928 - val_loss: 0.4409 - val_f2_score: 0.8521 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.3618 - f2_score: 0.8938 - val_loss: 0.4664 - val_f2_score: 0.8573 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.3528 - f2_score: 0.9029 - val_loss: 0.4481 - val_f2_score: 0.8318 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.3437 - f2_score: 0.9032 - val_loss: 0.4482 - val_f2_score: 0.8424 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.3354 - f2_score: 0.9045 - val_loss: 0.4456 - val_f2_score: 0.8197 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 8s 17ms/step - loss: 0.3236 - f2_score: 0.9055 - val_loss: 0.4403 - val_f2_score: 0.8521 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 7s 16ms/step - loss: 0.3114 - f2_score: 0.9161 - val_loss: 0.4358 - val_f2_score: 0.8369 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 7s 16ms/step - loss: 0.3092 - f2_score: 0.9122 - val_loss: 0.4309 - val_f2_score: 0.8788 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 8s 17ms/step - loss: 0.2941 - f2_score: 0.9201 - val_loss: 0.4389 - val_f2_score: 0.8404 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 8s 17ms/step - loss: 0.2908 - f2_score: 0.9153 - val_loss: 0.4344 - val_f2_score: 0.8700 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 8s 18ms/step - loss: 0.2795 - f2_score: 0.9210 - val_loss: 0.4342 - val_f2_score: 0.8831 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 7s 16ms/step - loss: 0.2769 - f2_score: 0.9187 - val_loss: 0.4363 - val_f2_score: 0.8335 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 7s 15ms/step - loss: 0.2643 - f2_score: 0.9229 - val_loss: 0.4285 - val_f2_score: 0.8558 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 7s 15ms/step - loss: 0.2518 - f2_score: 0.9289 - val_loss: 0.4330 - val_f2_score: 0.8791 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 8s 17ms/step - loss: 0.2464 - f2_score: 0.9324 - val_loss: 0.4465 - val_f2_score: 0.8643 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 7s 15ms/step - loss: 0.2411 - f2_score: 0.9368 - val_loss: 0.4454 - val_f2_score: 0.8446 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 7s 14ms/step - loss: 0.2313 - f2_score: 0.9376 - val_loss: 0.4776 - val_f2_score: 0.8683 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 7s 15ms/step - loss: 0.2274 - f2_score: 0.9363 - val_loss: 0.4592 - val_f2_score: 0.8788 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 5s 12ms/step - loss: 0.2086 - f2_score: 0.9467 - val_loss: 0.4583 - val_f2_score: 0.8722 - lr: 2.0000e-05\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.1989 - f2_score: 0.9513 - val_loss: 0.4676 - val_f2_score: 0.8745 - lr: 2.0000e-05\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.1972 - f2_score: 0.9520 - val_loss: 0.4620 - val_f2_score: 0.8760 - lr: 2.0000e-05\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.1948 - f2_score: 0.9506 - val_loss: 0.4589 - val_f2_score: 0.8639 - lr: 2.0000e-05\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.1959 - f2_score: 0.9534 - val_loss: 0.4662 - val_f2_score: 0.8691 - lr: 2.0000e-05\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.1897 - f2_score: 0.9547 - val_loss: 0.4614 - val_f2_score: 0.8638 - lr: 4.0000e-06\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.1865 - f2_score: 0.9560 - val_loss: 0.4657 - val_f2_score: 0.8652 - lr: 4.0000e-06\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.1846 - f2_score: 0.9578 - val_loss: 0.4660 - val_f2_score: 0.8694 - lr: 4.0000e-06\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.1903 - f2_score: 0.9532 - val_loss: 0.4655 - val_f2_score: 0.8687 - lr: 4.0000e-06\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.1852 - f2_score: 0.9587 - val_loss: 0.4658 - val_f2_score: 0.8656 - lr: 4.0000e-06\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.1862 - f2_score: 0.9544 - val_loss: 0.4676 - val_f2_score: 0.8701 - lr: 1.0000e-06\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.1830 - f2_score: 0.9572 - val_loss: 0.4688 - val_f2_score: 0.8726 - lr: 1.0000e-06\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.1879 - f2_score: 0.9533 - val_loss: 0.4665 - val_f2_score: 0.8694 - lr: 1.0000e-06\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.1850 - f2_score: 0.9564 - val_loss: 0.4672 - val_f2_score: 0.8687 - lr: 1.0000e-06\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.1847 - f2_score: 0.9533 - val_loss: 0.4683 - val_f2_score: 0.8694 - lr: 1.0000e-06\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.1839 - f2_score: 0.9607 - val_loss: 0.4673 - val_f2_score: 0.8694 - lr: 1.0000e-06\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.1826 - f2_score: 0.9582 - val_loss: 0.4685 - val_f2_score: 0.8692 - lr: 1.0000e-06\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.1864 - f2_score: 0.9553 - val_loss: 0.4676 - val_f2_score: 0.8665 - lr: 1.0000e-06\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.1822 - f2_score: 0.9559 - val_loss: 0.4691 - val_f2_score: 0.8692 - lr: 1.0000e-06\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 2s 5ms/step - loss: 0.1808 - f2_score: 0.9588 - val_loss: 0.4698 - val_f2_score: 0.8692 - lr: 1.0000e-06\n",
      "Epoch 53/100\n",
      "146/450 [========>.....................] - ETA: 1s - loss: 0.1883 - f2_score: 0.9471"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, min_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     57\u001b[0m f2_logger \u001b[38;5;241m=\u001b[39m F2ScoreLogger(validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val), threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m)\n\u001b[1;32m---> 59\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf2_logger\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m best_f2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(f2_logger\u001b[38;5;241m.\u001b[39mf2_scores)\n\u001b[0;32m     67\u001b[0m best_recall \u001b[38;5;241m=\u001b[39m f2_logger\u001b[38;5;241m.\u001b[39mrecalls[np\u001b[38;5;241m.\u001b[39margmax(f2_logger\u001b[38;5;241m.\u001b[39mf2_scores)]\n",
      "File \u001b[1;32mc:\\Users\\bhuri\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\bhuri\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bhuri\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bhuri\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bhuri\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\bhuri\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\bhuri\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bhuri\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\callbacks.py:1157\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\bhuri\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bhuri\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\bhuri\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\bhuri\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\Users\\bhuri\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\bhuri\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1124\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.makedirs(\"grid_search_outputs\", exist_ok=True)\n",
    "\n",
    "batch_sizes = [16]\n",
    "learning_rates = [0.0001, 0.0005, 0.001]\n",
    "hidden_units = [32, 64, 128]\n",
    "dropouts = [0.05, 0.1]\n",
    "kernel_regs = [0.01, 0.02]\n",
    "\n",
    "param_combinations = list(itertools.product(batch_sizes, learning_rates, hidden_units, dropouts, kernel_regs))\n",
    "\n",
    "results = []\n",
    "best_model = None\n",
    "best_model_config_id = None\n",
    "best_model_f2 = 0\n",
    "\n",
    "for i, (batch_size, lr, hidden_size, dropout_rate, kernel_reg) in enumerate(param_combinations):\n",
    "    fold_recalls = []\n",
    "    fold_f2_scores = []\n",
    "    fold_histories = []\n",
    "    fold_conf_matrices = []\n",
    "\n",
    "    for fold in range(5):\n",
    "        print(f\"Running config {i+1}/{len(param_combinations)}\")\n",
    "        print(\"Config:\")\n",
    "        print(f\"  Batch Size     : {batch_size}\")\n",
    "        print(f\"  Learning Rate  : {lr}\")\n",
    "        print(f\"  Hidden Units   : {hidden_size}\")\n",
    "        print(f\"  Dropout Rate   : {dropout_rate}\")\n",
    "        print(f\"  Kernel Reg L2  : {kernel_reg}\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Fold : {fold+1}\")\n",
    "\n",
    "        X_train, X_val = Train_data[fold], Val_data[fold]\n",
    "        y_train, y_val = Train_label[fold], Val_label[fold]\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        model = models.Sequential([\n",
    "            Input(shape=np.shape(Train_data[0][0])),\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(kernel_reg)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2(kernel_reg)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(hidden_size, activation='relu'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=[F2Score(name='f2_score')])\n",
    "        \n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6, verbose=0)\n",
    "        f2_logger = F2ScoreLogger(validation_data=(X_val, y_val), threshold=0.3)\n",
    "\n",
    "        history = model.fit(X_train, y_train,\n",
    "                            validation_data=(X_val, y_val),\n",
    "                            epochs=100,\n",
    "                            batch_size=batch_size,\n",
    "                            callbacks=[reduce_lr, f2_logger],\n",
    "                            verbose=1)\n",
    "\n",
    "        best_f2 = max(f2_logger.f2_scores)\n",
    "        best_recall = f2_logger.recalls[np.argmax(f2_logger.f2_scores)]\n",
    "\n",
    "        fold_recalls.append(best_recall)\n",
    "        fold_f2_scores.append(best_f2)\n",
    "        fold_histories.append(history)\n",
    "        y_pred = f2_logger.y_preds[fold]\n",
    "        cm = confusion_matrix(y_val, y_pred)\n",
    "        fold_conf_matrices.append((cm, y_val, y_pred))\n",
    "        \n",
    "        clear_output(wait=False)\n",
    "\n",
    "    best_fold = int(np.argmax(fold_f2_scores))\n",
    "    avg_f2 = np.mean(fold_f2_scores)\n",
    "    avg_recall = np.mean(fold_recalls)\n",
    "\n",
    "    best_history = fold_histories[best_fold]\n",
    "    best_cm, best_y_val, best_y_pred = fold_conf_matrices[best_fold]\n",
    "\n",
    "    results.append({\n",
    "        'config_id': i,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': lr,\n",
    "        'hidden_size': hidden_size,\n",
    "        'dropout': dropout_rate,\n",
    "        'kernel_reg': kernel_reg,\n",
    "        'avg_val_recall': avg_recall,\n",
    "        'best_recall': fold_recalls[best_fold],\n",
    "        'avg_val_f2': avg_f2,\n",
    "        'best_f2': fold_f2_scores[best_fold],\n",
    "        'history': best_history,\n",
    "        'confusion_matrix': best_cm\n",
    "    })\n",
    "\n",
    "    if avg_f2 > best_model_f2:\n",
    "        best_model_f2 = avg_f2\n",
    "        best_model_config_id = i\n",
    "        best_model = {\n",
    "            'history': best_history,\n",
    "            'confusion_matrix': best_cm,\n",
    "            'model': model\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5477322a-ee50-4fdf-ae92-450ac514676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results[best_model_config_id]\n",
    "\n",
    "print(\"Best Model Metric\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Config ID             : {best_model_config_id}\")\n",
    "print(f\"Batch Size            : {best_result['batch_size']}\")\n",
    "print(f\"Learning Rate         : {best_result['learning_rate']}\")\n",
    "print(f\"Hidden Units          : {best_result['hidden_size']}\")\n",
    "print(f\"Dropout Rate          : {best_result['dropout']}\")\n",
    "print(f\"Kernel Reg L2         : {best_result['kernel_reg']}\")\n",
    "print(f\"Avg Recall (5-fold)   : {best_result['avg_val_recall']:.4f}\")\n",
    "print(f\"Best Fold Recall      : {best_result['best_recall']:.4f}\")\n",
    "print(f\"Avg F2-score (5-fold) : {best_result['avg_val_f2']:.4f}\")\n",
    "print(f\"Best Fold F2-score    : {best_result['best_f2']:.4f}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "best_history = best_model['history']\n",
    "best_cm = best_model['confusion_matrix']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].plot(best_history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in best_history.history:\n",
    "    axes[0, 0].plot(best_history.history['val_loss'], label='Validation Loss')\n",
    "axes[0, 0].set_title('Model Loss')\n",
    "axes[0, 0].set_xlabel('Epochs')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "if 'f2_score' in best_history.history:\n",
    "    axes[0, 1].plot(best_history.history['f2_score'], label='Training F2 Score')\n",
    "if 'val_f2_score' in best_history.history:\n",
    "    axes[0, 1].plot(best_history.history['val_f2_score'], label='Validation F2 Score')\n",
    "axes[0, 1].set_title('Model F2 Score')\n",
    "axes[0, 1].set_xlabel('Epochs')\n",
    "axes[0, 1].set_ylabel('F2 Score')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "if 'lr' in best_history.history:\n",
    "    axes[1, 0].plot(best_history.history['lr'], label='Learning Rate')\n",
    "elif 'learning_rate' in best_history.history:\n",
    "    axes[1, 0].plot(best_history.history['learning_rate'], label='Learning Rate')\n",
    "axes[1, 0].set_title('Learning Rate')\n",
    "axes[1, 0].set_xlabel('Epochs')\n",
    "axes[1, 0].set_ylabel('Learning Rate')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=best_cm, display_labels=[\"Normal\", \"Abnormal\"])\n",
    "disp.plot(cmap=plt.cm.Blues, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Best Model Confusion Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b5823-1dbf-4e24-9019-7ca6399e8b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model['model'].save(f'../new_model/{Model_name}.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
