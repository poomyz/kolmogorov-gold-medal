{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e75e7a1-9ddd-4734-8ff9-424dee2dfc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import torch\n",
    "import itertools\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib as plt\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from kan.MultKAN import MultKAN\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b995d86-ca8f-4071-ad58-cddd7ffc7d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 7200, 256])\n",
      "torch.Size([5, 7200])\n",
      "torch.Size([5, 1800, 256])\n",
      "torch.Size([5, 1800])\n",
      "torch.Size([1000, 256])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "DATA_type = 'mels_kan_1'\n",
    "Model_name = 'kan_mels_1'\n",
    "Train_data = torch.load(f'../make_stored_data/sliding_window/{DATA_type}/Train_data.pt')\n",
    "Train_label = torch.load(f'../make_stored_data/sliding_window/{DATA_type}/Train_label.pt')\n",
    "Val_data = torch.load(f'../make_stored_data/sliding_window/{DATA_type}/Val_data.pt')\n",
    "Val_label = torch.load(f'../make_stored_data/sliding_window/{DATA_type}/Val_label.pt')\n",
    "Test_data = torch.load(f'../make_stored_data/sliding_window/{DATA_type}/Test_data.pt')\n",
    "Test_label = torch.load(f'../make_stored_data/sliding_window/{DATA_type}/Test_label.pt')\n",
    "print(np.shape(Train_data))\n",
    "print(np.shape(Train_label))\n",
    "print(np.shape(Val_data))\n",
    "print(np.shape(Val_label))\n",
    "print(np.shape(Test_data))\n",
    "print(np.shape(Test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db538c22-b56c-46b3-9699-5c174d4b4cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class F2Score(tf.keras.metrics.Metric):\n",
    "#     def __init__(self, name='f2_score', threshold=0.3, **kwargs):\n",
    "#         super(F2Score, self).__init__(name=name, **kwargs)\n",
    "#         self.threshold = threshold\n",
    "#         self.tp = self.add_weight(name='tp', initializer='zeros')\n",
    "#         self.fp = self.add_weight(name='fp', initializer='zeros')\n",
    "#         self.fn = self.add_weight(name='fn', initializer='zeros')\n",
    "\n",
    "#     def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "#         y_pred = tf.cast(y_pred > self.threshold, tf.float32)\n",
    "#         y_true = tf.cast(y_true, tf.float32)\n",
    "#         self.tp.assign_add(tf.reduce_sum(y_true * y_pred))\n",
    "#         self.fp.assign_add(tf.reduce_sum((1 - y_true) * y_pred))\n",
    "#         self.fn.assign_add(tf.reduce_sum(y_true * (1 - y_pred)))\n",
    "\n",
    "#     def result(self):\n",
    "#         precision = self.tp / (self.tp + self.fp + tf.keras.backend.epsilon())\n",
    "#         recall = self.tp / (self.tp + self.fn + tf.keras.backend.epsilon())\n",
    "#         return 5 * (precision * recall) / (4 * precision + recall + tf.keras.backend.epsilon())\n",
    "\n",
    "#     def reset_state(self):\n",
    "#         self.tp.assign(0)\n",
    "#         self.fp.assign(0)\n",
    "#         self.fn.assign(0)\n",
    "\n",
    "# class F2ScoreLogger(Callback):\n",
    "#     def __init__(self, validation_data, threshold=0.3):\n",
    "#         super().__init__()\n",
    "#         self.X_val, self.y_val = validation_data\n",
    "#         self.threshold = threshold\n",
    "#         self.y_preds = []\n",
    "#         self.f2_scores = []\n",
    "#         self.recalls = []\n",
    "#         self.precisions = []\n",
    "#         self.best_weights = None\n",
    "#         self.best_f2 = 0\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         y_pred_prob = self.model.predict(self.X_val, verbose=0)\n",
    "#         y_pred = (y_pred_prob > self.threshold).astype('int32')\n",
    "#         recall = recall_score(self.y_val, y_pred)\n",
    "#         precision = precision_score(self.y_val, y_pred)\n",
    "#         f2 = 5 / ((4 / recall) + (1 / precision)) if recall and precision else 0\n",
    "\n",
    "#         self.y_preds.append(y_pred)\n",
    "#         self.recalls.append(recall)\n",
    "#         self.precisions.append(precision)\n",
    "#         self.f2_scores.append(f2)\n",
    "\n",
    "#         if f2 > self.best_f2:\n",
    "#             self.best_f2 = f2\n",
    "#             self.best_weights = self.model.get_weights()\n",
    "\n",
    "#     def on_train_end(self, logs=None):\n",
    "#         if self.best_weights is not None:self.model.set_weights(self.best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71658a6d-a2b7-47da-b4fe-48f5cd8fcf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_sizes = [16]\n",
    "# learning_rates = [0.0001, 0.0005]\n",
    "# hidden_widths = [64, 128]\n",
    "# grids = [3, 5, 10]\n",
    "\n",
    "# param_combinations = list(itertools.product(batch_sizes, learning_rates, hidden_widths, grids))\n",
    "\n",
    "# results = []\n",
    "# best_model = None\n",
    "# best_model_config_id = None\n",
    "# best_model_f2 = 0\n",
    "\n",
    "# for i, (batch_size, lr, width, grid) in enumerate(param_combinations):\n",
    "#     fold_recalls = []\n",
    "#     fold_f2_scores = []\n",
    "#     fold_histories = []\n",
    "#     fold_conf_matrices = []\n",
    "\n",
    "#     for fold in range(5):\n",
    "#         best_f2 = 0\n",
    "#         print(f\"Running config {i+1}/{len(param_combinations)}\")\n",
    "#         print(\"Config:\")\n",
    "#         print(f\"  Batch Size     : {batch_size}\")\n",
    "#         print(f\"  Learning Rate  : {lr}\")\n",
    "#         print(f\"  Hidden Width   : {width}\")\n",
    "#         print(f\"  Grid           : {grid}\")\n",
    "#         print(\"-\" * 40)\n",
    "#         print(f\"Fold : {fold+1}\")\n",
    "\n",
    "#         X_train, X_val = Train_data[fold], Val_data[fold]\n",
    "#         y_train, y_val = Train_label[fold], Val_label[fold]\n",
    "\n",
    "#         model = MultKAN(width=[1024, width, 1], grid=grid, k=3, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "#         optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#         criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "#         for epoch in range(100):\n",
    "#             model.train()\n",
    "#             perm = torch.randperm(X_train.size(0))\n",
    "#             for step in range(0, X_train.size(0), batch_size):\n",
    "#                 indices = perm[step:step + batch_size]\n",
    "#                 X_batch = X_train[indices]\n",
    "#                 y_batch = y_train[indices]\n",
    "\n",
    "#                 optimizer.zero_grad()\n",
    "#                 y_pred = model(X_batch)\n",
    "#                 y_batch = y_batch.view(-1, 1).float()\n",
    "#                 loss = criterion(y_pred, y_batch)\n",
    "#                 loss.backward()\n",
    "#                 optimizer.step()\n",
    "#                 print('complete')\n",
    "\n",
    "#             model.eval()\n",
    "#             with torch.no_grad():\n",
    "#                 y_pred = model(X_val).cpu().numpy()\n",
    "#                 y_pred_bin = (y_pred > 0.3).astype(\"int32\")\n",
    "\n",
    "#             y_true = y_val.cpu().numpy().astype(\"int32\")\n",
    "\n",
    "#             recall = recall_score(y_true, y_pred_bin)\n",
    "#             precision = precision_score(y_true, y_pred_bin)\n",
    "#             f2 = 5 / ((4 / recall) + (1 / precision)) if recall and precision else 0\n",
    "            \n",
    "#             if f2 > best_f2:\n",
    "#                 best_f2 = f2\n",
    "#                 best_epoch_weights = model.state_dict()\n",
    "#                 best_epoch = epoch\n",
    "#             print(f'epoch {epoch} completed')\n",
    "\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             fold_y_pred = model(X_val).cpu().numpy()\n",
    "#             fold_y_pred_bin = (fold_y_pred > 0.3).astype(\"int32\")\n",
    "            \n",
    "#         fold_y_true = y_val.cpu().numpy().astype(\"int32\")\n",
    "\n",
    "#         fold_recall = recall_score(fold_y_true, fold_y_pred_bin)\n",
    "#         fold_precision = precision_score(fold_y_true, fold_y_pred_bin)\n",
    "#         fold_f2 = 5 / ((4 / fold_recall) + (1 / fold_precision)) if fold_recall and fold_precision else 0\n",
    "#         cm = confusion_matrix(fold_y_true, fold_y_pred_bin)\n",
    "\n",
    "#         fold_recalls.append(fold_recall)\n",
    "#         fold_f2_scores.append(fold_f2)\n",
    "#         fold_histories.append(history)\n",
    "#         fold_conf_matrices.append((cm, fold_y_true, fold_y_pred_bin))\n",
    "        \n",
    "#         clear_output(wait=False)\n",
    "\n",
    "#     best_fold = int(np.argmax(fold_f2_scores))\n",
    "#     avg_f2 = np.mean(fold_f2_scores)\n",
    "#     avg_recall = np.mean(fold_recalls)\n",
    "\n",
    "#     best_history = fold_histories[best_fold]\n",
    "#     best_cm, best_y_val, best_y_pred = fold_conf_matrices[best_fold]\n",
    "\n",
    "#     results.append({\n",
    "#         'config_id': i,\n",
    "#         'batch_size': batch_size,\n",
    "#         'learning_rate': lr,\n",
    "#         'hidden_size': hidden_size,\n",
    "#         'dropout': dropout_rate,\n",
    "#         'kernel_reg': kernel_reg,\n",
    "#         'avg_val_recall': avg_recall,\n",
    "#         'best_recall': fold_recalls[best_fold],\n",
    "#         'avg_val_f2': avg_f2,\n",
    "#         'best_f2': fold_f2_scores[best_fold],\n",
    "#         'history': best_history,\n",
    "#         'confusion_matrix': best_cm\n",
    "#     })\n",
    "\n",
    "#     if fold_f2_scores[best_fold] > best_model_f2:\n",
    "#         best_model_f2 = fold_f2_scores[best_fold]\n",
    "#         best_model_config_id = i\n",
    "#         best_model = {\n",
    "#             'history': best_history,\n",
    "#             'confusion_matrix': best_cm,\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8744513c-16e3-476e-92db-44dc9c909fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running config 1/9\n",
      "Config:\n",
      "  Grid   : 2\n",
      "  Lamb   : 0.001\n",
      "----------------------------------------\n",
      "Fold : 1\n",
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| train_loss: 5.00e-01 | test_loss: 5.00e-01 | reg: 7.55e-01 | :  19%|▏| 19/100 [04:37<19:43, 14.61s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 37\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# optimizer = optim.Adam(model.parameters(), lr=lr)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# criterion = nn.BCEWithLogitsLoss()\u001b[39;00m\n\u001b[0;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 37\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLBFGS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32m~\\PROJECT\\Kolmogorov readings\\sliding_window\\kan\\MultKAN.py:1555\u001b[0m, in \u001b[0;36mMultKAN.fit\u001b[1;34m(self, dataset, opt, steps, log, lamb, lamb_l1, lamb_entropy, lamb_coef, lamb_coefdiff, update_grid, grid_update_num, loss_fn, lr, start_grid_update_step, stop_grid_update_step, batch, metrics, save_fig, in_vars, out_vars, beta, save_fig_freq, img_folder, singularity_avoiding, y_th, reg_metric, display_metrics)\u001b[0m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_grid(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_input\u001b[39m\u001b[38;5;124m'\u001b[39m][train_id])\n\u001b[0;32m   1554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLBFGS\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1555\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1558\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_input\u001b[39m\u001b[38;5;124m'\u001b[39m][train_id], singularity_avoiding\u001b[38;5;241m=\u001b[39msingularity_avoiding, y_th\u001b[38;5;241m=\u001b[39my_th)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pykan-env\\lib\\site-packages\\torch\\optim\\optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m             )\n\u001b[1;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pykan-env\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\PROJECT\\Kolmogorov readings\\sliding_window\\kan\\LBFGS.py:443\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_directional_evaluate(closure, x, t, d)\n\u001b[1;32m--> 443\u001b[0m     loss, flat_grad, t, ls_func_evals \u001b[38;5;241m=\u001b[39m \u001b[43m_strong_wolfe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgtd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[0;32m    446\u001b[0m opt_cond \u001b[38;5;241m=\u001b[39m flat_grad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance_grad\n",
      "File \u001b[1;32m~\\PROJECT\\Kolmogorov readings\\sliding_window\\kan\\LBFGS.py:50\u001b[0m, in \u001b[0;36m_strong_wolfe\u001b[1;34m(obj_func, x, t, d, f, g, gtd, c1, c2, tolerance_change, max_ls)\u001b[0m\n\u001b[0;32m     48\u001b[0m g \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mclone(memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcontiguous_format)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# evaluate objective and gradient using initial step\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m f_new, g_new \u001b[38;5;241m=\u001b[39m \u001b[43mobj_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m ls_func_evals \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     52\u001b[0m gtd_new \u001b[38;5;241m=\u001b[39m g_new\u001b[38;5;241m.\u001b[39mdot(d)\n",
      "File \u001b[1;32m~\\PROJECT\\Kolmogorov readings\\sliding_window\\kan\\LBFGS.py:442\u001b[0m, in \u001b[0;36mLBFGS.step.<locals>.obj_func\u001b[1;34m(x, t, d)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mobj_func\u001b[39m(x, t, d):\n\u001b[1;32m--> 442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_directional_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\PROJECT\\Kolmogorov readings\\sliding_window\\kan\\LBFGS.py:291\u001b[0m, in \u001b[0;36mLBFGS._directional_evaluate\u001b[1;34m(self, closure, x, t, d)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_directional_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, closure, x, t, d):\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_grad(t, d)\n\u001b[1;32m--> 291\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    292\u001b[0m     flat_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather_flat_grad()\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_param(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pykan-env\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\PROJECT\\Kolmogorov readings\\sliding_window\\kan\\MultKAN.py:1521\u001b[0m, in \u001b[0;36mMultKAN.fit.<locals>.closure\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1519\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m train_loss, reg_\n\u001b[0;32m   1520\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m-> 1521\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_input\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingularity_avoiding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msingularity_avoiding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_th\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_th\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_label\u001b[39m\u001b[38;5;124m'\u001b[39m][train_id])\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_act:\n",
      "File \u001b[1;32m~\\PROJECT\\Kolmogorov readings\\sliding_window\\kan\\MultKAN.py:803\u001b[0m, in \u001b[0;36mMultKAN.forward\u001b[1;34m(self, x, singularity_avoiding, y_th)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macts\u001b[38;5;241m.\u001b[39mappend(x)  \u001b[38;5;66;03m# acts shape: (batch, width[l])\u001b[39;00m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth):\n\u001b[1;32m--> 803\u001b[0m     x_numerical, preacts, postacts_numerical, postspline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_fun\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m     \u001b[38;5;66;03m#print(preacts, postacts_numerical, postspline)\u001b[39;00m\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbolic_enabled \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pykan-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pykan-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\PROJECT\\Kolmogorov readings\\sliding_window\\kan\\KANLayer.py:157\u001b[0m, in \u001b[0;36mKANLayer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    154\u001b[0m preacts \u001b[38;5;241m=\u001b[39m x[:,\u001b[38;5;28;01mNone\u001b[39;00m,:]\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mexpand(batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_dim)\n\u001b[0;32m    156\u001b[0m base \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_fun(x) \u001b[38;5;66;03m# (batch, in_dim)\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcoef2curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m postspline \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    161\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_base[\u001b[38;5;28;01mNone\u001b[39;00m,:,:] \u001b[38;5;241m*\u001b[39m base[:,:,\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_sp[\u001b[38;5;28;01mNone\u001b[39;00m,:,:] \u001b[38;5;241m*\u001b[39m y\n",
      "File \u001b[1;32m~\\PROJECT\\Kolmogorov readings\\sliding_window\\kan\\spline.py:75\u001b[0m, in \u001b[0;36mcoef2curve\u001b[1;34m(x_eval, grid, coef, k, device)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcoef2curve\u001b[39m(x_eval, grid, coef, k, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m    converting B-spline coefficients to B-spline curves. Evaluate x on B-spline curves (summing up B_batch results over B-spline basis).\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m        \u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m     b_splines \u001b[38;5;241m=\u001b[39m \u001b[43mB_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     y_eval \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mijk,jlk->ijl\u001b[39m\u001b[38;5;124m'\u001b[39m, b_splines, coef\u001b[38;5;241m.\u001b[39mto(b_splines\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_eval\n",
      "File \u001b[1;32m~\\PROJECT\\Kolmogorov readings\\sliding_window\\kan\\spline.py:40\u001b[0m, in \u001b[0;36mB_batch\u001b[1;34m(x, grid, k, extend, device)\u001b[0m\n\u001b[0;32m     38\u001b[0m     value \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m grid[:, :, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m*\u001b[39m (x \u001b[38;5;241m<\u001b[39m grid[:, :, \u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 40\u001b[0m     B_km1 \u001b[38;5;241m=\u001b[39m \u001b[43mB_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     value \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m-\u001b[39m grid[:, :, :\u001b[38;5;241m-\u001b[39m(k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]) \u001b[38;5;241m/\u001b[39m (grid[:, :, k:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m grid[:, :, :\u001b[38;5;241m-\u001b[39m(k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]) \u001b[38;5;241m*\u001b[39m B_km1[:, :, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (\n\u001b[0;32m     43\u001b[0m                 grid[:, :, k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m-\u001b[39m x) \u001b[38;5;241m/\u001b[39m (grid[:, :, k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m-\u001b[39m grid[:, :, \u001b[38;5;241m1\u001b[39m:(\u001b[38;5;241m-\u001b[39mk)]) \u001b[38;5;241m*\u001b[39m B_km1[:, :, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# in case grid is degenerate\u001b[39;00m\n",
      "File \u001b[1;32m~\\PROJECT\\Kolmogorov readings\\sliding_window\\kan\\spline.py:42\u001b[0m, in \u001b[0;36mB_batch\u001b[1;34m(x, grid, k, extend, device)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     B_km1 \u001b[38;5;241m=\u001b[39m B_batch(x[:,:,\u001b[38;5;241m0\u001b[39m], grid\u001b[38;5;241m=\u001b[39mgrid[\u001b[38;5;241m0\u001b[39m], k\u001b[38;5;241m=\u001b[39mk \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 42\u001b[0m     value \u001b[38;5;241m=\u001b[39m (\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;241m/\u001b[39m (grid[:, :, k:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m grid[:, :, :\u001b[38;5;241m-\u001b[39m(k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)]) \u001b[38;5;241m*\u001b[39m B_km1[:, :, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (\n\u001b[0;32m     43\u001b[0m                 grid[:, :, k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m-\u001b[39m x) \u001b[38;5;241m/\u001b[39m (grid[:, :, k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m-\u001b[39m grid[:, :, \u001b[38;5;241m1\u001b[39m:(\u001b[38;5;241m-\u001b[39mk)]) \u001b[38;5;241m*\u001b[39m B_km1[:, :, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# in case grid is degenerate\u001b[39;00m\n\u001b[0;32m     46\u001b[0m value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnan_to_num(value)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grids = [2, 3, 4]\n",
    "lambs = [0.001, 0.002, 0.003]\n",
    "\n",
    "param_combinations = list(itertools.product(grids, lambs))\n",
    "\n",
    "results = []\n",
    "best_model = None\n",
    "best_model_config_id = None\n",
    "best_model_f2 = 0\n",
    "\n",
    "for i, (grid, lamb) in enumerate(param_combinations):\n",
    "    fold_recalls = []\n",
    "    fold_f2_scores = []\n",
    "    fold_histories = []\n",
    "    fold_conf_matrices = []\n",
    "\n",
    "    for fold in range(5):\n",
    "        best_f2 = 0\n",
    "        print(f\"Running config {i+1}/{len(param_combinations)}\")\n",
    "        print(\"Config:\")\n",
    "        print(f\"  Grid   : {grid}\")\n",
    "        print(f\"  Lamb   : {lamb}\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Fold : {fold+1}\")\n",
    "\n",
    "        X_train, X_val = Train_data[fold], Val_data[fold]\n",
    "        y_train, y_val = Train_label[fold], Val_label[fold]\n",
    "\n",
    "        dataset = {'train_input': X_train, 'train_label': y_train, 'test_input': X_val, 'test_label': y_val}\n",
    "\n",
    "        model = MultKAN(width=[256, 5, 1], grid=grid, k=3, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "        \n",
    "        # optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        # criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        model.train()\n",
    "        model.fit(dataset, opt=\"LBFGS\", steps=50, lamb=lamb)\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            fold_y_pred = model(X_val).cpu().numpy()\n",
    "            fold_y_pred_bin = (fold_y_pred > 0.3).astype(\"int32\")\n",
    "            \n",
    "        fold_y_true = y_val.cpu().numpy().astype(\"int32\")\n",
    "\n",
    "        fold_recall = recall_score(fold_y_true, fold_y_pred_bin)\n",
    "        fold_precision = precision_score(fold_y_true, fold_y_pred_bin)\n",
    "        fold_f2 = 5 / ((4 / fold_recall) + (1 / fold_precision)) if fold_recall and fold_precision else 0\n",
    "        cm = confusion_matrix(fold_y_true, fold_y_pred_bin)\n",
    "\n",
    "        fold_recalls.append(fold_recall)\n",
    "        fold_f2_scores.append(fold_f2)\n",
    "        fold_histories.append(history)\n",
    "        fold_conf_matrices.append((cm, fold_y_true, fold_y_pred_bin))\n",
    "        \n",
    "        clear_output(wait=False)\n",
    "\n",
    "    best_fold = int(np.argmax(fold_f2_scores))\n",
    "    avg_f2 = np.mean(fold_f2_scores)\n",
    "    avg_recall = np.mean(fold_recalls)\n",
    "\n",
    "    best_history = fold_histories[best_fold]\n",
    "    best_cm, best_y_val, best_y_pred = fold_conf_matrices[best_fold]\n",
    "\n",
    "    results.append({\n",
    "        'config_id': i,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': lr,\n",
    "        'hidden_size': hidden_size,\n",
    "        'dropout': dropout_rate,\n",
    "        'kernel_reg': kernel_reg,\n",
    "        'avg_val_recall': avg_recall,\n",
    "        'best_recall': fold_recalls[best_fold],\n",
    "        'avg_val_f2': avg_f2,\n",
    "        'best_f2': fold_f2_scores[best_fold],\n",
    "        'history': best_history,\n",
    "        'confusion_matrix': best_cm\n",
    "    })\n",
    "\n",
    "    if fold_f2_scores[best_fold] > best_model_f2:\n",
    "        best_model_f2 = fold_f2_scores[best_fold]\n",
    "        best_model_config_id = i\n",
    "        best_model = {\n",
    "            'history': best_history,\n",
    "            'confusion_matrix': best_cm,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5477322a-ee50-4fdf-ae92-450ac514676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = results[best_model_config_id]\n",
    "\n",
    "print(\"Best Model Metric\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Config ID             : {best_model_config_id}\")\n",
    "print(f\"Batch Size            : {best_result['batch_size']}\")\n",
    "print(f\"Learning Rate         : {best_result['learning_rate']}\")\n",
    "print(f\"Hidden Units          : {best_result['hidden_size']}\")\n",
    "print(f\"Dropout Rate          : {best_result['dropout']}\")\n",
    "print(f\"Kernel Reg L2         : {best_result['kernel_reg']}\")\n",
    "print(f\"Avg Recall (5-fold)   : {best_result['avg_val_recall']:.4f}\")\n",
    "print(f\"Best Fold Recall      : {best_result['best_recall']:.4f}\")\n",
    "print(f\"Avg F2-score (5-fold) : {best_result['avg_val_f2']:.4f}\")\n",
    "print(f\"Best Fold F2-score    : {best_result['best_f2']:.4f}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "best_history = best_model['history']\n",
    "best_cm = best_model['confusion_matrix']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "axes[0, 0].plot(best_history.history['loss'], label='Training Loss')\n",
    "if 'val_loss' in best_history.history:\n",
    "    axes[0, 0].plot(best_history.history['val_loss'], label='Validation Loss')\n",
    "axes[0, 0].set_title('Model Loss')\n",
    "axes[0, 0].set_xlabel('Epochs')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "if 'f2_score' in best_history.history:\n",
    "    axes[0, 1].plot(best_history.history['f2_score'], label='Training F2 Score')\n",
    "if 'val_f2_score' in best_history.history:\n",
    "    axes[0, 1].plot(best_history.history['val_f2_score'], label='Validation F2 Score')\n",
    "axes[0, 1].set_title('Model F2 Score')\n",
    "axes[0, 1].set_xlabel('Epochs')\n",
    "axes[0, 1].set_ylabel('F2 Score')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "if 'lr' in best_history.history:\n",
    "    axes[1, 0].plot(best_history.history['lr'], label='Learning Rate')\n",
    "elif 'learning_rate' in best_history.history:\n",
    "    axes[1, 0].plot(best_history.history['learning_rate'], label='Learning Rate')\n",
    "axes[1, 0].set_title('Learning Rate')\n",
    "axes[1, 0].set_xlabel('Epochs')\n",
    "axes[1, 0].set_ylabel('Learning Rate')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=best_cm, display_labels=[\"Normal\", \"Abnormal\"])\n",
    "disp.plot(cmap=plt.cm.Blues, ax=axes[1, 1])\n",
    "axes[1, 1].set_title(\"Best Model Confusion Matrix (Validation)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8a8d65-04db-4303-9efc-e083dcb833bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(f2_logger.best_weights)\n",
    "Test_pred = (model.predict(Test_data) > 0.3).astype(\"int32\")\n",
    "\n",
    "Test_acc = accuracy_score(Test_label, Test_pred)\n",
    "Test_precision = precision_score(Test_label, Test_pred)\n",
    "Test_recall = recall_score(Test_label, Test_pred)\n",
    "Test_f2 = 5 / ((4 / Test_recall) + (1 / Test_precision)) if Test_recall and Test_precision else 0\n",
    "Test_cm = confusion_matrix(Test_label, Test_pred)\n",
    "\n",
    "print(\"=== Test Set Performance ===\")\n",
    "print(f\"Accuracy  : {Test_acc:.4f}\")\n",
    "print(f\"Precision : {Test_precision:.4f}\")\n",
    "print(f\"Recall    : {Test_recall:.4f}\")\n",
    "print(f\"F2 Score  : {Test_f2:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "\n",
    "Test_disp = ConfusionMatrixDisplay(confusion_matrix=Test_cm, display_labels=[\"Normal\", \"Abnormal\"])\n",
    "Test_disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Best Model Confusion Matrix (Test)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b5823-1dbf-4e24-9019-7ca6399e8b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f'../new_model/{Model_name}.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
